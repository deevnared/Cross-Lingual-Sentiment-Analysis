{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwxPmTHRC2yq",
        "outputId": "64b7fb10-2138-42d9-a52f-93d11890612a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VlY36UgMkVG",
        "outputId": "4d33f513-f802-46e4-cbbb-205747209e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "test.review  train.review  unlabeled.review\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to the zip file in your Google Drive\n",
        "zip_file_path = '/content/drive/My Drive/cls-acl10-unprocessed.zip'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset')\n",
        "\n",
        "# Verify extraction\n",
        "!ls /content/dataset/cls-acl10-unprocessed/en/books\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "rHcHK6sCtFuz",
        "outputId": "bbab7db7-00de-4128-aa10-eef9d5a2a635"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  While I realize that the majority of people th...      0\n",
              "1  I had never read any of  Vernor Vinges books b...      0\n",
              "2  I got this as both a book and an audio file.  ...      0\n",
              "3  The content of this book is adequate, but the ...      0\n",
              "4  This book can be very damaging if you approach...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5940ec35-1416-4fa1-859d-a34ece4ab43b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>While I realize that the majority of people th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I had never read any of  Vernor Vinges books b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I got this as both a book and an audio file.  ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The content of this book is adequate, but the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This book can be very damaging if you approach...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5940ec35-1416-4fa1-859d-a34ece4ab43b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5940ec35-1416-4fa1-859d-a34ece4ab43b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5940ec35-1416-4fa1-859d-a34ece4ab43b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-06392146-deff-4bc5-a92a-fc18f213b628\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-06392146-deff-4bc5-a92a-fc18f213b628')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-06392146-deff-4bc5-a92a-fc18f213b628 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1985,\n        \"samples\": [\n          \"One of the best novels I have ever read.  This book has everything a good read should:  characters that become real to the reader, a wonderful sense of place, a sense of history and knowledge.  Not only do you get completely wrapped up in the world of Vine Sullivan, but you also learn more about yourself in the process.  A truly beautiful book that I can't recommend highly enough.  I've bought a copy for everyone I love\\n\",\n          \"The book I read was Championship Ball, by Clair Bee. Championship Ball is about a high school basketball player named Chip. Chip is an extremely good athlete and is a starting basketball player for his high school. Everything was going great until something happened that would change Chips life forever. During a basketball game Chip got tripped up and hit the ground hard. As Chip was writhing in pain, the team trainer came out to assist him. As it turned out Chip had fractured his ankle in several places. It was pretty bad which would mean that he would have to watch the games from the team bench for the rest of the year most likely. As his team goes on without him, they are doing quite well. They are making a championship run, and they are doing quite well, and they eventually get there. Before the big championship game, Chip was begging his coach to let him play. Chip's coach is not sure if Chip is\\n ready to play just yet, but Chip is by far the best athlete on the team. Will Chip get to play in the big game, or will he have to spend yet another game spectating from the bench.\\n I really enjoyed the book because it is very suspenseful, and it is hard to put down. It is suspenseful because throughout the book the author does not tell you Chips condition in its entirety, and whether or not he will get to play in the up coming games. There was on thing that I did not like about the book and that is the repetitiveness. It seemed like every time a big game was about to unfold, the same thing happened on the court. Also every time Chip asked his coach to play, he always said no, so you kind of almost expect it. \\n My strongest reason for recommending this book is that it is very well put together. Also if you are into sports or you like suspense and action, then you will probably love this book because it has all of these aspects.\\n\",\n          \"Not very well known, but one of the most important artists in his styl\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def parse_review(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    reviews = []\n",
        "\n",
        "    for item in root.findall('item'):\n",
        "        rating = float(item.find('rating').text)  # Convert rating to float\n",
        "        text = item.find('text').text\n",
        "        label = 1 if rating > 3.0 else 0  # Positive if rating > 3.0, otherwise negative\n",
        "        reviews.append({'text': text, 'label': label})\n",
        "\n",
        "    return pd.DataFrame(reviews)\n",
        "\n",
        "# Load the English books reviews\n",
        "train_df = parse_review('/content/dataset/cls-acl10-unprocessed/en/books/train.review')\n",
        "test_df = parse_review('/content/dataset/cls-acl10-unprocessed/en/books/test.review')\n",
        "\n",
        "# Display the first few rows\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dImX9JWMwisO",
        "outputId": "26d488ae-d8e8-410a-fa68-8e595896e4c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.7575\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.74      0.75       198\n",
            "           1       0.75      0.77      0.76       202\n",
            "\n",
            "    accuracy                           0.76       400\n",
            "   macro avg       0.76      0.76      0.76       400\n",
            "weighted avg       0.76      0.76      0.76       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_df['text'], train_df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the text data using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred = model.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f'Validation Accuracy: {accuracy}')\n",
        "print(classification_report(y_val, y_val_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2SDUxugMxA3S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "S8nePoQszHrD",
        "outputId": "4b457c42-5c66-41f8-ec21-0c011694d411"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [text, rating]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57025ccb-9afa-4c5d-a827-3ba6cd2fff49\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57025ccb-9afa-4c5d-a827-3ba6cd2fff49')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57025ccb-9afa-4c5d-a827-3ba6cd2fff49 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57025ccb-9afa-4c5d-a827-3ba6cd2fff49');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "reviews_df",
              "summary": "{\n  \"name\": \"reviews_df\",\n  \"rows\": 0,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def read_reviews_from_directory(directory):\n",
        "    reviews = {'text': [], 'rating': []}\n",
        "    for file_name in ['train.review', 'test.review', 'unlabeled.review']:\n",
        "        file_path = os.path.join(directory, file_name)\n",
        "        if os.path.exists(file_path):\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                for line in file:\n",
        "                    # XML parsing logic\n",
        "                    start_text = line.find('<text>') + len('<text>')\n",
        "                    end_text = line.find('</text>')\n",
        "                    text = line[start_text:end_text].strip()\n",
        "                    start_rating = line.find('<rating>') + len('<rating>')\n",
        "                    end_rating = line.find('</rating>')\n",
        "                    rating = int(line[start_rating:end_rating].strip())\n",
        "\n",
        "                    reviews['text'].append(text)\n",
        "                    reviews['rating'].append(rating)\n",
        "\n",
        "    return pd.DataFrame(reviews)\n",
        "\n",
        "# Load the English dataset\n",
        "data_directory = '/content/dataset/cls-acl10-unprocessed/en'\n",
        "reviews_df = read_reviews_from_directory(data_directory)\n",
        "\n",
        "# Check the loaded data\n",
        "reviews_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl1Y-zNqzeVA",
        "outputId": "053b5e5d-e5cf-4442-b7d3-bbd1d57814c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading as CSV\n",
            "First few rows of data:\n",
            "Empty DataFrame\n",
            "Columns: [text, rating]\n",
            "Index: []\n",
            "Error reading as TSV\n",
            "First few rows of data:\n",
            "Empty DataFrame\n",
            "Columns: [text, rating]\n",
            "Index: []\n",
            "File loaded successfully with custom delimiter '|'\n",
            "First few rows of data:\n",
            "              <?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
            "0                                      <items><item>\n",
            "1      \\t<summary>Insert pun with word \"con\" here...\n",
            "2                                         </summary>\n",
            "3                             \\t<rating>2.0</rating>\n",
            "4  \\t<text>\"Con Express\" has lots of action in it...\n",
            "File read as plain text\n",
            "First few lines of data:\n",
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
            "\n",
            "<items><item>\n",
            "\n",
            "\t<summary>Insert pun with word \"con\" here...\n",
            "\n",
            "</summary>\n",
            "\n",
            "\t<rating>2.0</rating>\n",
            "\n",
            "\t<text>\"Con Express\" has lots of action in it, which is great because this hides the poor writing and uninteresting characters. Unfortunately, the action isn't enough, and in between stunt pieces and shoot-outs, the audience is tempted to doze off. City Heat Productions isn't really known for producing films of the highest quality, so usually I go easy on them. If this were a big-budget company producing this, I'd be inclined to pan it entirely. But I wasn't expecting much and got a little more than I bargained for. The action is, for the most part, pretty good but nothing competitive with your usual dumb action movie. Flanery and Vosloo are perfectly casted, but everyone else seems to stiff to add any more flow to the movie. Vosloo especially appears to be enjoying himself as an over-the-top bad guy hijacking a train containing deadly chemicals. The film moves fast and contains shades of better movies like Under Siege 2, Con Air, Spy Game, and Speed. If you liked those, you probably won't mind this one too much. Just go easy on it\n",
            "\n",
            "</text>\n",
            "\n",
            "\t<category>dvd</category>\n",
            "\n",
            "\t</item>\n",
            "\n",
            "<item>\n",
            "\n",
            "Data columns:\n",
            "Index(['<?xml version=\"1.0\" encoding=\"utf-8\"?>'], dtype='object')\n",
            "Data types:\n",
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>    object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define file path\n",
        "file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/train.review'\n",
        "\n",
        "# Try reading the file with different methods\n",
        "\n",
        "# Method 1: Attempt to read as CSV with default delimiter (comma)\n",
        "try:\n",
        "    reviews_df = pd.read_csv(file_path)\n",
        "    print(\"File loaded successfully as CSV\")\n",
        "except pd.errors.ParserError:\n",
        "    print(\"Error reading as CSV\")\n",
        "\n",
        "# Check the first few rows to understand the data structure\n",
        "print(\"First few rows of data:\")\n",
        "print(reviews_df.head())\n",
        "\n",
        "# Method 2: If CSV fails, try tab-separated values (TSV)\n",
        "try:\n",
        "    reviews_df = pd.read_csv(file_path, delimiter='\\t')\n",
        "    print(\"File loaded successfully as TSV\")\n",
        "except pd.errors.ParserError:\n",
        "    print(\"Error reading as TSV\")\n",
        "\n",
        "# Check the first few rows to understand the data structure\n",
        "print(\"First few rows of data:\")\n",
        "print(reviews_df.head())\n",
        "\n",
        "# Method 3: If TSV fails, try custom delimiter (e.g., '|')\n",
        "try:\n",
        "    reviews_df = pd.read_csv(file_path, delimiter='|')\n",
        "    print(\"File loaded successfully with custom delimiter '|'\")\n",
        "except pd.errors.ParserError:\n",
        "    print(\"Error reading with custom delimiter\")\n",
        "\n",
        "# Check the first few rows to understand the data structure\n",
        "print(\"First few rows of data:\")\n",
        "print(reviews_df.head())\n",
        "\n",
        "# Method 4: If all else fails, read as plain text and inspect manually\n",
        "try:\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    print(\"File read as plain text\")\n",
        "    print(\"First few lines of data:\")\n",
        "    for line in lines[:10]:\n",
        "        print(line)\n",
        "except Exception as e:\n",
        "    print(f\"Error reading file: {e}\")\n",
        "\n",
        "# After loading the file successfully, proceed with data analysis\n",
        "# For example, checking the data types and columns\n",
        "if 'reviews_df' in locals():\n",
        "    print(\"Data columns:\")\n",
        "    print(reviews_df.columns)\n",
        "    print(\"Data types:\")\n",
        "    print(reviews_df.dtypes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "id": "4nCPXdqR0u_w",
        "outputId": "ce89493c-60fa-40f6-a2d2-406ca15f8d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame created successfully:\n",
            "                                                text rating sentiment\n",
            "0  \"Con Express\" has lots of action in it, which ...    2.0  negative\n",
            "1  It is obvious that this movie is full of lies....    1.0  negative\n",
            "2  I don't want to spoil this movie for others an...    1.0  negative\n",
            "3  If there is one thing Michael Bay is good at, ...    1.0  negative\n",
            "4  About the only thing this movie has going for ...    2.0  negative\n",
            "Number of rows in DataFrame: 2000\n",
            "Columns in DataFrame: Index(['text', 'rating', 'sentiment'], dtype='object')\n",
            "Sentiment distribution:\n",
            "sentiment\n",
            "negative    1000\n",
            "positive    1000\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load and read the plain text file\n",
        "file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/train.review'\n",
        "with open(file_path, 'r') as file:\n",
        "    xml_content = file.read()\n",
        "\n",
        "# Remove XML declaration if present\n",
        "xml_content = re.sub(r'^<\\?xml.*\\?>', '', xml_content).strip()\n",
        "\n",
        "# Wrap the content with a root element\n",
        "xml_content = f\"<root>{xml_content}</root>\"\n",
        "\n",
        "# Parse the XML content\n",
        "try:\n",
        "    root = ET.fromstring(xml_content)\n",
        "except ET.ParseError as e:\n",
        "    print(f\"XML Parse Error: {e}\")\n",
        "    root = None\n",
        "\n",
        "# Extract data\n",
        "data = []\n",
        "if root is not None:\n",
        "    for item in root.findall(\".//item\"):\n",
        "        text = item.find(\"text\").text.strip() if item.find(\"text\") is not None else \"\"\n",
        "        rating = item.find(\"rating\").text.strip() if item.find(\"rating\") is not None else \"\"\n",
        "        sentiment = \"positive\" if float(rating) > 3.0 else \"negative\"  # Simple sentiment classification based on rating\n",
        "        data.append({'text': text, 'rating': rating, 'sentiment': sentiment})\n",
        "\n",
        "# Convert to DataFrame\n",
        "reviews_df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"DataFrame created successfully:\")\n",
        "print(reviews_df.head())\n",
        "\n",
        "# Check for empty DataFrame\n",
        "if reviews_df.empty:\n",
        "    print(\"DataFrame is empty.\")\n",
        "else:\n",
        "    print(f\"Number of rows in DataFrame: {len(reviews_df)}\")\n",
        "    print(f\"Columns in DataFrame: {reviews_df.columns}\")\n",
        "\n",
        "# Check sentiment distribution\n",
        "sentiment_counts = reviews_df['sentiment'].value_counts()\n",
        "print(\"Sentiment distribution:\")\n",
        "print(sentiment_counts)\n",
        "\n",
        "# Plot sentiment distribution (optional)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sentiment_counts.plot(kind='bar', color=['blue', 'red'])\n",
        "plt.title('Sentiment Distribution')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psERNxFsM8ql",
        "outputId": "20546133-395f-46ee-c1de-5c20640e5cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "29/29 [==============================] - 18s 453ms/step - loss: 0.1725 - accuracy: 0.9822 - val_loss: 1.3496e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "29/29 [==============================] - 10s 357ms/step - loss: 8.1209e-05 - accuracy: 1.0000 - val_loss: 5.8939e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "29/29 [==============================] - 12s 421ms/step - loss: 5.3816e-05 - accuracy: 1.0000 - val_loss: 4.9339e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "29/29 [==============================] - 16s 552ms/step - loss: 4.6045e-05 - accuracy: 1.0000 - val_loss: 4.2278e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "29/29 [==============================] - 12s 433ms/step - loss: 3.9560e-05 - accuracy: 1.0000 - val_loss: 3.7125e-05 - val_accuracy: 1.0000\n",
            "63/63 [==============================] - 7s 98ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00      2000\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      1.00      1.00      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:2326: UserWarning: labels size, 1, does not match size of target_names, 2\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2860/2860 [==============================] - 228s 80ms/step\n",
            "                                                text          sentiment  \\\n",
            "0  X MEN ORIGINS : WOLVERINE präsentiert uns die ...  DVD &amp; Blu-ray   \n",
            "1  Komme gerade aus dem Kino. Großartiger Film.\\n...  DVD &amp; Blu-ray   \n",
            "2  Für mich und meine Lebensgefährtin war der Fil...  DVD &amp; Blu-ray   \n",
            "3  Ich finde das der Film an sich schon sehenswer...  DVD &amp; Blu-ray   \n",
            "4  Illuminati gehört für  mich ganz klar zu eines...  DVD &amp; Blu-ray   \n",
            "\n",
            "  predicted_sentiment  \n",
            "0            negative  \n",
            "1            negative  \n",
            "2            negative  \n",
            "3            negative  \n",
            "4            negative  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.metrics import classification_report\n",
        "import re\n",
        "\n",
        "# Function to parse XML data\n",
        "def parse_xml(file_path):\n",
        "    reviews = []\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    for item in root.findall('item'):\n",
        "        text = item.find('text').text if item.find('text') is not None else ''\n",
        "        sentiment = item.find('category').text if item.find('category') is not None else ''\n",
        "        reviews.append((text, sentiment))\n",
        "    return reviews\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_data(language, category):\n",
        "    train_file = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/train.review'\n",
        "    test_file = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/test.review'\n",
        "    unlabeled_file = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/unlabeled.review'\n",
        "\n",
        "    train_reviews = parse_xml(train_file)\n",
        "    test_reviews = parse_xml(test_file)\n",
        "    unlabeled_reviews = parse_xml(unlabeled_file)\n",
        "\n",
        "    train_df = pd.DataFrame(train_reviews, columns=['text', 'sentiment'])\n",
        "    test_df = pd.DataFrame(test_reviews, columns=['text', 'sentiment'])\n",
        "    unlabeled_df = pd.DataFrame(unlabeled_reviews, columns=['text', 'sentiment'])\n",
        "\n",
        "    return train_df, test_df, unlabeled_df\n",
        "\n",
        "# Preprocess text data\n",
        "def preprocess_text(texts):\n",
        "    cleaned_texts = []\n",
        "    for text in texts:\n",
        "        if isinstance(text, str):\n",
        "            text = re.sub(r'<[^>]+>', '', text)  # Remove XML tags\n",
        "            text = text.strip()  # Remove leading/trailing whitespace\n",
        "        else:\n",
        "            text = ''  # Convert None to empty string\n",
        "        cleaned_texts.append(text)\n",
        "    return cleaned_texts\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "def tokenize_and_pad(train_texts, test_texts, max_len=100):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "    X_train_seq = tokenizer.texts_to_sequences(train_texts)\n",
        "    X_test_seq = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "    X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "    X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "    return X_train_pad, X_test_pad, tokenizer\n",
        "\n",
        "# Convert labels to numeric values\n",
        "def labels_to_numeric(labels):\n",
        "    return [1 if label == 'positive' else 0 for label in labels]\n",
        "\n",
        "# Build LSTM model\n",
        "def build_lstm_model(vocab_size, max_len):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, 128, input_length=max_len))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Main process for German language\n",
        "language = 'de'  # German language\n",
        "category = 'dvd'  # Example: DVDs\n",
        "\n",
        "train_df, test_df, unlabeled_df = load_data(language, category)\n",
        "\n",
        "train_texts = preprocess_text(train_df['text'].tolist())\n",
        "test_texts = preprocess_text(test_df['text'].tolist())\n",
        "unlabeled_texts = preprocess_text(unlabeled_df['text'].tolist())\n",
        "\n",
        "X_train_pad, X_test_pad, tokenizer = tokenize_and_pad(train_texts, test_texts)\n",
        "y_train = np.array(labels_to_numeric(train_df['sentiment']))\n",
        "y_test = np.array(labels_to_numeric(test_df['sentiment']))\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_len = X_train_pad.shape[1]\n",
        "\n",
        "model = build_lstm_model(vocab_size, max_len)\n",
        "model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test_pad)\n",
        "y_pred_labels = [1 if p > 0.5 else 0 for p in y_pred]\n",
        "\n",
        "# Ensure both classes are present in the labels\n",
        "labels = np.unique(y_test)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred_labels, target_names=['negative', 'positive'], labels=labels))\n",
        "\n",
        "# Predict on unlabeled data\n",
        "X_unlabeled_seq = tokenizer.texts_to_sequences(unlabeled_texts)\n",
        "X_unlabeled_pad = pad_sequences(X_unlabeled_seq, maxlen=max_len)\n",
        "unlabeled_pred = model.predict(X_unlabeled_pad)\n",
        "unlabeled_pred_labels = ['positive' if p > 0.5 else 'negative' for p in unlabeled_pred]\n",
        "\n",
        "# Add predictions to DataFrame\n",
        "unlabeled_df['predicted_sentiment'] = unlabeled_pred_labels\n",
        "print(unlabeled_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns_psmDcQE1W",
        "outputId": "27b2f7c1-f1a2-4943-8c48-663629354215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_sentiment\n",
            "negative    91516\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Count the number of each sentiment in the 'predicted_sentiment' column\n",
        "sentiment_counts = unlabeled_df['predicted_sentiment'].value_counts()\n",
        "print(sentiment_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDcuKc_QStk_",
        "outputId": "cff427ec-77be-49d0-b6a3-d92be47d5445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
            "<items><item>\n",
            "\t<summary>Insert pun with word \"con\" here...\n",
            "</summary>\n",
            "\t<rating>2.0</rating>\n",
            "\t<text>\"Con Express\" has lots of action in it, which is great because this hides the poor writing and uninteresting characters. Unfortunately, the action isn't enough, and in between stunt pieces and shoot-outs, the audience is tempted to doze off. City Heat Productions isn't really known for producing films of the highest quality, so usually I go easy on them. If this were a big-budget company producing this, I'd be inclined to pan it entirely. But I wasn't expecting much and got a little more than I bargained for. The action is, for the most part, pretty good but nothing competitive with your usual dumb action movie. Flanery and Vosloo are perfectly casted, but everyone else seems to stiff to add any more flow to the movie. Vosloo especially appears to be enjoying himself as an over-the-top bad guy hijacking a train containing deadly chemicals. The film moves fast and contains shades of better movies like Under Siege 2, Con Air, Spy Game, and Speed. If you liked those, you probably won't mind this one too much. Just go easy on it\n",
            "</text>\n",
            "\t<category>dvd</category>\n",
            "\t</item>\n",
            "<item>\n"
          ]
        }
      ],
      "source": [
        "!head -n 10 /content/dataset/cls-acl10-unprocessed/en/dvd/train.review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtI_M-wUiMCi",
        "outputId": "2b3e6804-90f5-464a-f6ba-079aac4e57a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Head:\n",
            " Empty DataFrame\n",
            "Columns: [text, sentiment]\n",
            "Index: []\n",
            "Test Data Head:\n",
            " Empty DataFrame\n",
            "Columns: [text, sentiment]\n",
            "Index: []\n",
            "Unlabeled Data Head:\n",
            " Empty DataFrame\n",
            "Columns: [text, sentiment]\n",
            "Index: []\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 0 entries\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   text       0 non-null      object\n",
            " 1   sentiment  0 non-null      object\n",
            "dtypes: object(2)\n",
            "memory usage: 124.0+ bytes\n",
            "Train Data Info:\n",
            " None\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    data = []\n",
        "    for review in root.findall('review'):\n",
        "        sentiment = review.get('polarity')\n",
        "        text = review.find('text').text\n",
        "        data.append((text, sentiment))\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['text', 'sentiment'])\n",
        "    return df\n",
        "\n",
        "train_df = parse_xml('/content/dataset/cls-acl10-unprocessed/en/dvd/train.review')\n",
        "test_df = parse_xml('/content/dataset/cls-acl10-unprocessed/en/dvd/test.review')\n",
        "unlabeled_df = parse_xml('/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled.review')\n",
        "\n",
        "print(\"Train Data Head:\\n\", train_df.head())\n",
        "print(\"Test Data Head:\\n\", test_df.head())\n",
        "print(\"Unlabeled Data Head:\\n\", unlabeled_df.head())\n",
        "print(\"Train Data Info:\\n\", train_df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84sqPTZahweW",
        "outputId": "42f25cef-d534-4d73-90d6-dce4c932f70d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted Train Sentiments:\n",
            " Series([], Name: count, dtype: int64)\n",
            "Converted Test Sentiments:\n",
            " Series([], Name: count, dtype: int64)\n"
          ]
        }
      ],
      "source": [
        "train_df['sentiment'] = train_df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "test_df['sentiment'] = test_df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "\n",
        "print(\"Converted Train Sentiments:\\n\", train_df['sentiment'].value_counts())\n",
        "print(\"Converted Test Sentiments:\\n\", test_df['sentiment'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqz5No3Iiu_S",
        "outputId": "09ab705f-7bca-458f-b313-55fd6baa6fcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Train Texts: []\n",
            "Preprocessed Test Texts: []\n",
            "Preprocessed Unlabeled Texts: []\n"
          ]
        }
      ],
      "source": [
        "def preprocess_text(texts):\n",
        "    # Add your text preprocessing steps here\n",
        "    return [text.lower() for text in texts if text is not None]\n",
        "\n",
        "train_texts = preprocess_text(train_df['text'].tolist())\n",
        "test_texts = preprocess_text(test_df['text'].tolist())\n",
        "unlabeled_texts = preprocess_text(unlabeled_df['text'].tolist())\n",
        "\n",
        "print(\"Preprocessed Train Texts:\", train_texts[:5])\n",
        "print(\"Preprocessed Test Texts:\", test_texts[:5])\n",
        "print(\"Preprocessed Unlabeled Texts:\", unlabeled_texts[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br4abYPoixMM",
        "outputId": "e1e2250f-b87f-4abd-c43d-bf417dfaf141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded Train Sequences Shape: (0, 200)\n",
            "Padded Test Sequences Shape: (0, 200)\n",
            "Padded Unlabeled Sequences Shape: (0, 200)\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_words = 10000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(train_texts)\n",
        "X_test_seq = tokenizer.texts_to_sequences(test_texts)\n",
        "X_unlabeled_seq = tokenizer.texts_to_sequences(unlabeled_texts)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "X_unlabeled_pad = pad_sequences(X_unlabeled_seq, maxlen=max_len)\n",
        "\n",
        "print(\"Padded Train Sequences Shape:\", X_train_pad.shape)\n",
        "print(\"Padded Test Sequences Shape:\", X_test_pad.shape)\n",
        "print(\"Padded Unlabeled Sequences Shape:\", X_unlabeled_pad.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHM5DIZ1i0B9",
        "outputId": "87737b78-4a6f-4b6e-ea68-55227616701b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Labels: []\n",
            "Test Labels: []\n",
            "Train Labels Shape: (0,)\n",
            "Test Labels Shape: (0,)\n"
          ]
        }
      ],
      "source": [
        "y_train = train_df['sentiment'].values\n",
        "y_test = test_df['sentiment'].values\n",
        "\n",
        "print(\"Train Labels:\", y_train[:5])\n",
        "print(\"Test Labels:\", y_test[:5])\n",
        "print(\"Train Labels Shape:\", y_train.shape)\n",
        "print(\"Test Labels Shape:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9JecK1ei2am",
        "outputId": "6cd3f799-ce8c-4dac-84f6-a3e2a2ccd3ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data is empty. Please check the data preprocessing steps.\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "if len(y_train) > 0 and len(X_train_pad) > 0:\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_words, 128, input_length=max_len))\n",
        "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test_pad)\n",
        "    y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    from sklearn.metrics import classification_report\n",
        "    print(classification_report(y_test, y_pred_labels, target_names=['negative', 'positive']))\n",
        "\n",
        "    # Predict on unlabeled data\n",
        "    unlabeled_pred = model.predict(X_unlabeled_pad)\n",
        "    unlabeled_pred_labels = (unlabeled_pred > 0.5).astype(int)\n",
        "\n",
        "    unlabeled_df['predicted_sentiment'] = ['positive' if label == 1 else 'negative' for label in unlabeled_pred_labels]\n",
        "    print(unlabeled_df['predicted_sentiment'].value_counts())\n",
        "else:\n",
        "    print(\"Training data is empty. Please check the data preprocessing steps.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qrch47bii554",
        "outputId": "2b03bbfd-38d1-4de7-e9ab-6dbb91af9ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Review Content:\n",
            "Test Review Content:\n",
            "Unlabeled Review Content:\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def print_xml_file_content(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    for review in root.findall('review')[:5]:  # Print the first 5 reviews\n",
        "        sentiment = review.get('polarity')\n",
        "        text = review.find('text').text\n",
        "        print(f'Sentiment: {sentiment}, Text: {text[:100]}...')  # Print only the first 100 characters of the text\n",
        "\n",
        "print(\"Train Review Content:\")\n",
        "print_xml_file_content('/content/dataset/cls-acl10-unprocessed/en/dvd/train.review')\n",
        "\n",
        "print(\"Test Review Content:\")\n",
        "print_xml_file_content('/content/dataset/cls-acl10-unprocessed/en/dvd/test.review')\n",
        "\n",
        "print(\"Unlabeled Review Content:\")\n",
        "print_xml_file_content('/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled.review')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxytEmqejIe7",
        "outputId": "bce6f1a0-c85a-49e4-f73d-65d3f486f0b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Content of Train Review File:\n",
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
            "<items><item>\n",
            "\t<summary>Insert pun with word \"con\" here...\n",
            "</summary>\n",
            "\t<rating>2.0</rating>\n",
            "\t<text>\"Con Express\" has lots of action in it, which is great because this hides the poor writing and uninteresting characters. Unfortunately, the action isn't enough, and in between stunt pieces and shoot-outs, the audience is tempted to doze off. City Heat Productions isn't really known for producing films of the highest quality, so usually I go easy on them. If this were a big-budget company producing this, I'd be inclined to pan it entirely. But I wasn't expecting much and got a little more than I bargained for. The action is, for the most part, pretty good but nothing competitive with your usual dumb action movie. Flanery and Vosloo are perfectly casted, but everyone else seems to stiff to add any more flow to the movie. Vosloo especially appears to be enjoying himself as an over-the-top bad guy hijacking a train containing deadly chemicals. The film m\n",
            "Raw Content of Test Review File:\n",
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
            "<items><item>\n",
            "\t<summary>kitsch is global\n",
            "</summary>\n",
            "\t<rating>1.0</rating>\n",
            "\t<text>A 130-minute barrage of unrelieved bathos and sentimentality, this Swedish import doesn't so much insult your intelligence as complacently assume that you never had any in the first place, wouldn't know what to do with it if you did have it, and in general favor entertainment that bypasses the brain entirely and addresses itself directly to the tear ducts. The plot is of the type commonly described in laudatory reviews as \"well-worn,\" which seems to be a euphemism for \"shop-worn,\" \"clichï¿½,\" or \"stupefyingly unoriginal.\" Here it is (spoilers follow): Daniel, a big-shot conductor in emotional difficulties and poor health, returns to the quaint rural village of his childhood, takes over and revives the local church choir, heals himself and everyone else in sight with his life-affirming yet charmingly diffident zaniness, finds love, finds his inner child, and finally, a\n",
            "Raw Content of Unlabeled Review File:\n",
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
            "<items><item>\n",
            "\t<summary>A Major Disappointment \n",
            "</summary>\n",
            "\t<rating>2.0</rating>\n",
            "\t<text>I expected so much more from this movie, I guess since the cast included two of my favorite actors (Jolie &amp; Washington) and also had the always on point Queen Latifah as well.  I watched with full expectation to absolutely love this movie, but I walked away bitter with shattered expectations.  First off I will say that Latifah was wonderful here and she proved as the only reason I smiled on occasion during this movie experience.  Washington and Jolie on the other hand were so unbelievable (especially Washington who really strained in this role) that I was constantly asking myself \"do I really like these two?\" and I had to remind myself of movies like 'Gia' and 'Training Day' to answer with a resounding \"YES!\"\n",
            " \n",
            " The film follows a rookie cop (Jolie) as she helps a quadriplegic ex-cop Lincoln (Washington) track down a serial killer mimicking the killings det\n"
          ]
        }
      ],
      "source": [
        "def print_raw_xml_content(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "        print(content[:1000])  # Print the first 1000 characters\n",
        "\n",
        "print(\"Raw Content of Train Review File:\")\n",
        "print_raw_xml_content('/content/dataset/cls-acl10-unprocessed/en/dvd/train.review')\n",
        "\n",
        "print(\"Raw Content of Test Review File:\")\n",
        "print_raw_xml_content('/content/dataset/cls-acl10-unprocessed/en/dvd/test.review')\n",
        "\n",
        "print(\"Raw Content of Unlabeled Review File:\")\n",
        "print_raw_xml_content('/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled.review')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhyHjMK2jZn-",
        "outputId": "bf291b22-fb96-4065-9672-067de496b5d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame saved to CSV:\n",
            "Empty DataFrame\n",
            "Columns: [text, sentiment]\n",
            "Index: []\n",
            "Test DataFrame saved to CSV:\n",
            "Empty DataFrame\n",
            "Columns: [text, sentiment]\n",
            "Index: []\n",
            "Unlabeled DataFrame saved to CSV:\n",
            "Empty DataFrame\n",
            "Columns: [text, sentiment]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    data = []\n",
        "    for review in root.findall('review'):\n",
        "        sentiment = review.get('polarity')\n",
        "        text = review.find('text').text\n",
        "        if text is not None:  # Ensure text is not None\n",
        "            data.append((text, sentiment))\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['text', 'sentiment'])\n",
        "    return df\n",
        "\n",
        "# Define file paths\n",
        "train_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/train.review'\n",
        "test_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/test.review'\n",
        "unlabeled_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled.review'\n",
        "\n",
        "# Parse XML files\n",
        "train_df = parse_xml_to_df(train_file_path)\n",
        "test_df = parse_xml_to_df(test_file_path)\n",
        "unlabeled_df = parse_xml_to_df(unlabeled_file_path)\n",
        "\n",
        "# Save to CSV\n",
        "train_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/train.csv'\n",
        "test_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/test.csv'\n",
        "unlabeled_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled.csv'\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "unlabeled_df.to_csv(unlabeled_csv_path, index=False)\n",
        "\n",
        "print(\"Train DataFrame saved to CSV:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"Test DataFrame saved to CSV:\")\n",
        "print(test_df.head())\n",
        "\n",
        "print(\"Unlabeled DataFrame saved to CSV:\")\n",
        "print(unlabeled_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maKlaLGuju1F",
        "outputId": "b1a44769-76d6-4163-d45a-552cd961bde2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame saved to CSV:\n",
            "Empty DataFrame\n",
            "Columns: [text, sentiment]\n",
            "Index: []\n",
            "Test DataFrame saved to CSV:\n",
            "Empty DataFrame\n",
            "Columns: [text, sentiment]\n",
            "Index: []\n",
            "Unlabeled DataFrame saved to CSV:\n",
            "Empty DataFrame\n",
            "Columns: [text, sentiment]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    data = []\n",
        "    for review in root.findall('review'):\n",
        "        sentiment = review.get('polarity')\n",
        "        text = review.find('text').text\n",
        "        if text is not None:  # Ensure text is not None\n",
        "            data.append((text, sentiment))\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['text', 'sentiment'])\n",
        "    return df\n",
        "\n",
        "# Define file paths\n",
        "train_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/train.review'\n",
        "test_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/test.review'\n",
        "unlabeled_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled.review'\n",
        "\n",
        "# Parse XML files\n",
        "train_df = parse_xml_to_df(train_file_path)\n",
        "test_df = parse_xml_to_df(test_file_path)\n",
        "unlabeled_df = parse_xml_to_df(unlabeled_file_path)\n",
        "\n",
        "# Save to CSV\n",
        "train_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/train.csv'\n",
        "test_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/test.csv'\n",
        "unlabeled_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled.csv'\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "unlabeled_df.to_csv(unlabeled_csv_path, index=False)\n",
        "\n",
        "print(\"Train DataFrame saved to CSV:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"Test DataFrame saved to CSV:\")\n",
        "print(test_df.head())\n",
        "\n",
        "print(\"Unlabeled DataFrame saved to CSV:\")\n",
        "print(unlabeled_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNnMG2IBkOgp",
        "outputId": "a1d51eac-1579-41db-f027-dca6fd10abf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame saved to CSV:\n",
            "                                   summary  \\\n",
            "0       Insert pun with word \"con\" here...   \n",
            "1                                    Lies!   \n",
            "2                       watching paint dry   \n",
            "3             Explosions & Animal Crackers   \n",
            "4  A good soundtrack in search of a movie.   \n",
            "\n",
            "                                                text category  \n",
            "0  \"Con Express\" has lots of action in it, which ...      dvd  \n",
            "1  It is obvious that this movie is full of lies....      dvd  \n",
            "2  I don't want to spoil this movie for others an...      dvd  \n",
            "3  If there is one thing Michael Bay is good at, ...      dvd  \n",
            "4  About the only thing this movie has going for ...      dvd  \n",
            "Test DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0                                   kitsch is global   \n",
            "1   Chapellle didnt want to do these for a reason...   \n",
            "2                        Enough of too much awready!   \n",
            "3                             The Trinity Collection   \n",
            "4  It's about kids at a \"musical camp\" for wannab...   \n",
            "\n",
            "                                                text category  \n",
            "0  A 130-minute barrage of unrelieved bathos and ...      dvd  \n",
            "1  They SUCK! Bad writing and jokes that rely on ...      dvd  \n",
            "2  The population of Hong Kong is approximately 7...      dvd  \n",
            "3  The movies and stories are classic westerns, t...      dvd  \n",
            "4  These are not your typical teens. They love Br...      dvd  \n",
            "Unlabeled DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0                             A Major Disappointment   \n",
            "1           Looks like a routine television program.   \n",
            "2  Not enough Natalie and certainly not enough bu...   \n",
            "3                                      Soo primitive   \n",
            "4  What the hell is this?  A movie about doing dr...   \n",
            "\n",
            "                                                text category  \n",
            "0  I expected so much more from this movie, I gue...      dvd  \n",
            "1  I am amazed and mystified that most of the rev...      dvd  \n",
            "2  I suppose it's alright if you like overlong mu...      dvd  \n",
            "3  The movie is a about a guy, who does a lot of ...      dvd  \n",
            "4  Maybe it's because I had never read the book a...      dvd  \n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    data = []\n",
        "    for item in root.findall('item'):\n",
        "        summary = item.find('summary').text\n",
        "        text = item.find('text').text\n",
        "        category = item.find('category').text\n",
        "\n",
        "        if summary is not None and text is not None and category is not None:\n",
        "            data.append((summary.strip(), text.strip(), category.strip()))\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['summary', 'text', 'category'])\n",
        "    return df\n",
        "\n",
        "# Define file paths\n",
        "train_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/train.review'\n",
        "test_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/test.review'\n",
        "unlabeled_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled.review'\n",
        "\n",
        "# Parse XML files\n",
        "train_df = parse_xml_to_df(train_file_path)\n",
        "test_df = parse_xml_to_df(test_file_path)\n",
        "unlabeled_df = parse_xml_to_df(unlabeled_file_path)\n",
        "\n",
        "# Save to CSV\n",
        "train_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/train.csv'\n",
        "test_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/test.csv'\n",
        "unlabeled_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled.csv'\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "unlabeled_df.to_csv(unlabeled_csv_path, index=False)\n",
        "\n",
        "print(\"Train DataFrame saved to CSV:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"Test DataFrame saved to CSV:\")\n",
        "print(test_df.head())\n",
        "\n",
        "print(\"Unlabeled DataFrame saved to CSV:\")\n",
        "print(unlabeled_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veGQvrtalfpz",
        "outputId": "7e6da521-aea9-4a60-9a3d-e2525d5c04f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Music DataFrame saved to CSV:\n",
            "                                 summary  \\\n",
            "0                What! Ja WHO? Can't be!   \n",
            "1          Not the music from this movie   \n",
            "2  Stick To The Movie, THAT was a treat!   \n",
            "3                           clapton suck   \n",
            "4                              Dreadful!   \n",
            "\n",
            "                                                text category  \n",
            "0  This is not what I expected from such a gifted...    music  \n",
            "1  This is not the music from the movie. This pur...    music  \n",
            "2  Get's one star in appreciation of the technici...    music  \n",
            "3  Layla is one of the most overrated songs of al...    music  \n",
            "4  I don't understand the previous reviews - I fo...    music  \n",
            "Test Music DataFrame saved to CSV:\n",
            "          summary                                               text category\n",
            "0  No Good At All  Completely worthless! If you liked the film, g...    music\n",
            "1  Recycled goods  Having listened to Steven's previous albums, G...    music\n",
            "2      TICKED OFF  I bought this cd after hearing Tony on one of ...    music\n",
            "3  Better Stoned?  Um. I have nothing against bands that are \"mai...    music\n",
            "4   Born to Croon  Jeff Buckley sounds like what Marc Bolan would...    music\n",
            "Unlabeled Music DataFrame saved to CSV:\n",
            "                           summary  \\\n",
            "0                  What can I say?   \n",
            "1  not quite ready for prime time.   \n",
            "2                    Disapointment   \n",
            "3                         ooo lord   \n",
            "4              Boo them off stage.   \n",
            "\n",
            "                                                text category  \n",
            "0  I've always held the philosophy you are what y...    music  \n",
            "1  someone get this band a producer and put them ...    music  \n",
            "2  Tihs Album is not all that good when it came o...    music  \n",
            "3  this industry is \"goin down\"  \\n \\n u call thi...    music  \n",
            "4  I'm sorry but the guy below me doesn't know mu...    music  \n",
            "Train Books DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0           Possibly the worst book I have ever read   \n",
            "1               BORING WITH A TOTAL  LACK OF CLARITY   \n",
            "2  Author sneaks in biblical misinterpretation, p...   \n",
            "3                                    Horrible Layout   \n",
            "4                            Please be very careful!   \n",
            "\n",
            "                                                text category  \n",
            "0  While I realize that the majority of people th...    books  \n",
            "1  I had never read any of  Vernor Vinges books b...    books  \n",
            "2  I got this as both a book and an audio file.  ...    books  \n",
            "3  The content of this book is adequate, but the ...    books  \n",
            "4  This book can be very damaging if you approach...    books  \n",
            "Test Books DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0                           Good history, but.......   \n",
            "1                                  Refinement Needed   \n",
            "2                                             A Bore   \n",
            "3  What was country about the majority of the sto...   \n",
            "4                                   suks comepletely   \n",
            "\n",
            "                                                text category  \n",
            "0  No doubt about it.  This book covers the histo...    books  \n",
            "1  There's a ton of paper in this book, overboard...    books  \n",
            "2  Each story has a different author...however th...    books  \n",
            "3  A book full of heartwarming stories from count...    books  \n",
            "4  this joke book suks. if i can give it any star...    books  \n",
            "Unlabeled Books DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0  I had a bad feeling about this!  And I was right!   \n",
            "1  The book felt more like the author was forced ...   \n",
            "2               Reading shouldn't have to be a chore   \n",
            "3                                           Revenge!   \n",
            "4              Too Graphic-Too Long to get somewhere   \n",
            "\n",
            "                                                text category  \n",
            "0  I was intrigued by the title, which supposedly...    books  \n",
            "1  Why is it ever time you want something bad eno...    books  \n",
            "2  Once upon a time I was given a vanity-publishe...    books  \n",
            "3  Let me see how many books can I write to preac...    books  \n",
            "4  This book was so different from the usual NR s...    books  \n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    data = []\n",
        "    for item in root.findall('item'):\n",
        "        summary = item.find('summary').text\n",
        "        text = item.find('text').text\n",
        "        category = item.find('category').text\n",
        "\n",
        "        if summary is not None and text is not None and category is not None:\n",
        "            data.append((summary.strip(), text.strip(), category.strip()))\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['summary', 'text', 'category'])\n",
        "    return df\n",
        "\n",
        "# Define file paths for music\n",
        "train_music_path = '/content/dataset/cls-acl10-unprocessed/en/music/train.review'\n",
        "test_music_path = '/content/dataset/cls-acl10-unprocessed/en/music/test.review'\n",
        "unlabeled_music_path = '/content/dataset/cls-acl10-unprocessed/en/music/unlabeled.review'\n",
        "\n",
        "# Parse XML files for music\n",
        "train_music_df = parse_xml_to_df(train_music_path)\n",
        "test_music_df = parse_xml_to_df(test_music_path)\n",
        "unlabeled_music_df = parse_xml_to_df(unlabeled_music_path)\n",
        "\n",
        "# Save to CSV for music\n",
        "train_music_csv_path = '/content/dataset/cls-acl10-unprocessed/en/music/train.csv'\n",
        "test_music_csv_path = '/content/dataset/cls-acl10-unprocessed/en/music/test.csv'\n",
        "unlabeled_music_csv_path = '/content/dataset/cls-acl10-unprocessed/en/music/unlabeled.csv'\n",
        "\n",
        "train_music_df.to_csv(train_music_csv_path, index=False)\n",
        "test_music_df.to_csv(test_music_csv_path, index=False)\n",
        "unlabeled_music_df.to_csv(unlabeled_music_csv_path, index=False)\n",
        "\n",
        "print(\"Train Music DataFrame saved to CSV:\")\n",
        "print(train_music_df.head())\n",
        "\n",
        "print(\"Test Music DataFrame saved to CSV:\")\n",
        "print(test_music_df.head())\n",
        "\n",
        "print(\"Unlabeled Music DataFrame saved to CSV:\")\n",
        "print(unlabeled_music_df.head())\n",
        "\n",
        "# Define file paths for books\n",
        "train_books_path = '/content/dataset/cls-acl10-unprocessed/en/books/train.review'\n",
        "test_books_path = '/content/dataset/cls-acl10-unprocessed/en/books/test.review'\n",
        "unlabeled_books_path = '/content/dataset/cls-acl10-unprocessed/en/books/unlabeled.review'\n",
        "\n",
        "# Parse XML files for books\n",
        "train_books_df = parse_xml_to_df(train_books_path)\n",
        "test_books_df = parse_xml_to_df(test_books_path)\n",
        "unlabeled_books_df = parse_xml_to_df(unlabeled_books_path)\n",
        "\n",
        "# Save to CSV for books\n",
        "train_books_csv_path = '/content/dataset/cls-acl10-unprocessed/en/books/train.csv'\n",
        "test_books_csv_path = '/content/dataset/cls-acl10-unprocessed/en/books/test.csv'\n",
        "unlabeled_books_csv_path = '/content/dataset/cls-acl10-unprocessed/en/books/unlabeled.csv'\n",
        "\n",
        "train_books_df.to_csv(train_books_csv_path, index=False)\n",
        "test_books_df.to_csv(test_books_csv_path, index=False)\n",
        "unlabeled_books_df.to_csv(unlabeled_books_csv_path, index=False)\n",
        "\n",
        "print(\"Train Books DataFrame saved to CSV:\")\n",
        "print(train_books_df.head())\n",
        "\n",
        "print(\"Test Books DataFrame saved to CSV:\")\n",
        "print(test_books_df.head())\n",
        "\n",
        "print(\"Unlabeled Books DataFrame saved to CSV:\")\n",
        "print(unlabeled_books_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjlUFTJomkvM",
        "outputId": "3bb4f068-c58b-4674-8198-0041e023e120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['summary', 'text', 'category'], dtype='object')\n",
            "Index(['summary', 'text', 'category'], dtype='object')\n",
            "Index(['summary', 'text', 'category'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(train_df.columns)\n",
        "print(test_df.columns)\n",
        "print(unlabeled_df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUtCWEi4nDjx",
        "outputId": "9e6f5f9b-0e51-43eb-e019-ba9c64f94aa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame saved to CSV:\n",
            "                                     summary  \\\n",
            "0       Insert pun with word \"con\" here...\\n   \n",
            "1                                    Lies!\\n   \n",
            "2                       watching paint dry\\n   \n",
            "3             Explosions & Animal Crackers\\n   \n",
            "4  A good soundtrack in search of a movie.\\n   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  \"Con Express\" has lots of action in it, which ...      dvd  negative  \n",
            "1  It is obvious that this movie is full of lies....      dvd  negative  \n",
            "2  I don't want to spoil this movie for others an...      dvd  negative  \n",
            "3  If there is one thing Michael Bay is good at, ...      dvd  negative  \n",
            "4  About the only thing this movie has going for ...      dvd  negative  \n",
            "Test DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0                                 kitsch is global\\n   \n",
            "1  Chapellle didnt want to do these for a reason....   \n",
            "2                      Enough of too much awready!\\n   \n",
            "3                           The Trinity Collection\\n   \n",
            "4  It's about kids at a \"musical camp\" for wannab...   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  A 130-minute barrage of unrelieved bathos and ...      dvd  negative  \n",
            "1  They SUCK! Bad writing and jokes that rely on ...      dvd  negative  \n",
            "2  The population of Hong Kong is approximately 7...      dvd  negative  \n",
            "3  The movies and stories are classic westerns, t...      dvd  negative  \n",
            "4  These are not your typical teens. They love Br...      dvd  negative  \n",
            "Unlabeled DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0                          A Major Disappointment \\n   \n",
            "1         Looks like a routine television program.\\n   \n",
            "2  Not enough Natalie and certainly not enough bu...   \n",
            "3                                    Soo primitive\\n   \n",
            "4  What the hell is this?  A movie about doing dr...   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  I expected so much more from this movie, I gue...      dvd  negative  \n",
            "1  I am amazed and mystified that most of the rev...      dvd  negative  \n",
            "2  I suppose it's alright if you like overlong mu...      dvd  negative  \n",
            "3  The movie is a about a guy, who does a lot of ...      dvd  negative  \n",
            "4  Maybe it's because I had never read the book a...      dvd  negative  \n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for item in root.findall('item'):\n",
        "        summary = item.find('summary').text if item.find('summary') is not None else \"\"\n",
        "        text = item.find('text').text if item.find('text') is not None else \"\"\n",
        "        category = item.find('category').text if item.find('category') is not None else \"\"\n",
        "        rating = item.find('rating').text if item.find('rating') is not None else None\n",
        "        if rating is not None:\n",
        "            rating = float(rating)\n",
        "            sentiment = 'positive' if rating > 2 else 'negative'\n",
        "            data.append((summary, text, category, sentiment))\n",
        "    df = pd.DataFrame(data, columns=['summary', 'text', 'category', 'sentiment'])\n",
        "    return df\n",
        "\n",
        "# Define file paths\n",
        "train_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/train.review'\n",
        "test_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/test.review'\n",
        "unlabeled_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled.review'\n",
        "\n",
        "# Parse XML files\n",
        "train_df = parse_xml_to_df(train_file_path)\n",
        "test_df = parse_xml_to_df(test_file_path)\n",
        "unlabeled_df = parse_xml_to_df(unlabeled_file_path)\n",
        "\n",
        "# Save to CSV\n",
        "train_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/train.csv'\n",
        "test_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/test.csv'\n",
        "unlabeled_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled.csv'\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "unlabeled_df.to_csv(unlabeled_csv_path, index=False)\n",
        "\n",
        "print(\"Train DataFrame saved to CSV:\")\n",
        "print(train_df.head())\n",
        "print(\"Test DataFrame saved to CSV:\")\n",
        "print(test_df.head())\n",
        "print(\"Unlabeled DataFrame saved to CSV:\")\n",
        "print(unlabeled_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLPs3GTNngI0",
        "outputId": "3dc433ad-5ebe-44a0-c7bc-0eee985dad54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Train sentiment counts:\n",
            "sentiment\n",
            "negative    1000\n",
            "positive    1000\n",
            "Name: count, dtype: int64\n",
            "Test sentiment counts:\n",
            "sentiment\n",
            "negative    1000\n",
            "positive    1000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(train_df.columns)\n",
        "print(test_df.columns)\n",
        "print(unlabeled_df.columns)\n",
        "\n",
        "# Count positive and negative sentiments in train and test data\n",
        "print(\"Train sentiment counts:\")\n",
        "print(train_df['sentiment'].value_counts())\n",
        "\n",
        "print(\"Test sentiment counts:\")\n",
        "print(test_df['sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN6-7nFyny26",
        "outputId": "b807ce2d-5503-450f-fdc1-49b44ac0d499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame saved to CSV:\n",
            "                                     summary  \\\n",
            "0       Insert pun with word \"con\" here...\\n   \n",
            "1                                    Lies!\\n   \n",
            "2                       watching paint dry\\n   \n",
            "3             Explosions & Animal Crackers\\n   \n",
            "4  A good soundtrack in search of a movie.\\n   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  \"Con Express\" has lots of action in it, which ...      dvd   neutral  \n",
            "1  It is obvious that this movie is full of lies....      dvd  negative  \n",
            "2  I don't want to spoil this movie for others an...      dvd  negative  \n",
            "3  If there is one thing Michael Bay is good at, ...      dvd  negative  \n",
            "4  About the only thing this movie has going for ...      dvd   neutral  \n",
            "Test DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0                                 kitsch is global\\n   \n",
            "1  Chapellle didnt want to do these for a reason....   \n",
            "2                      Enough of too much awready!\\n   \n",
            "3                           The Trinity Collection\\n   \n",
            "4  It's about kids at a \"musical camp\" for wannab...   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  A 130-minute barrage of unrelieved bathos and ...      dvd  negative  \n",
            "1  They SUCK! Bad writing and jokes that rely on ...      dvd  negative  \n",
            "2  The population of Hong Kong is approximately 7...      dvd   neutral  \n",
            "3  The movies and stories are classic westerns, t...      dvd  negative  \n",
            "4  These are not your typical teens. They love Br...      dvd   neutral  \n",
            "Unlabeled DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0                          A Major Disappointment \\n   \n",
            "1         Looks like a routine television program.\\n   \n",
            "2  Not enough Natalie and certainly not enough bu...   \n",
            "3                                    Soo primitive\\n   \n",
            "4  What the hell is this?  A movie about doing dr...   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  I expected so much more from this movie, I gue...      dvd   neutral  \n",
            "1  I am amazed and mystified that most of the rev...      dvd  negative  \n",
            "2  I suppose it's alright if you like overlong mu...      dvd   neutral  \n",
            "3  The movie is a about a guy, who does a lot of ...      dvd   neutral  \n",
            "4  Maybe it's because I had never read the book a...      dvd  negative  \n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Train sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     574\n",
            "neutral      426\n",
            "Name: count, dtype: int64\n",
            "Test sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     577\n",
            "neutral      423\n",
            "Name: count, dtype: int64\n",
            "Epoch 1/5\n",
            "25/25 [==============================] - 13s 347ms/step - loss: 1.0504 - accuracy: 0.4869 - val_loss: 1.0065 - val_accuracy: 0.5175\n",
            "Epoch 2/5\n",
            "25/25 [==============================] - 10s 408ms/step - loss: 0.9014 - accuracy: 0.5606 - val_loss: 0.8520 - val_accuracy: 0.6325\n",
            "Epoch 3/5\n",
            "25/25 [==============================] - 10s 398ms/step - loss: 0.6155 - accuracy: 0.7144 - val_loss: 0.8433 - val_accuracy: 0.6400\n",
            "Epoch 4/5\n",
            "25/25 [==============================] - 8s 309ms/step - loss: 0.4106 - accuracy: 0.8338 - val_loss: 1.0335 - val_accuracy: 0.6225\n",
            "Epoch 5/5\n",
            "25/25 [==============================] - 10s 408ms/step - loss: 0.2082 - accuracy: 0.9144 - val_loss: 1.2421 - val_accuracy: 0.6100\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 1.2926 - accuracy: 0.6005\n",
            "Test Accuracy: 0.6004999876022339\n",
            "938/938 [==============================] - 74s 79ms/step\n",
            "Unlabeled predicted sentiment counts:\n",
            "predicted_sentiment\n",
            "negative    15433\n",
            "positive    10623\n",
            "neutral      3944\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for item in root.findall('item'):\n",
        "        summary = item.find('summary').text if item.find('summary') is not None else \"\"\n",
        "        text = item.find('text').text if item.find('text') is not None else \"\"\n",
        "        category = item.find('category').text if item.find('category') is not None else \"\"\n",
        "        rating = item.find('rating').text if item.find('rating') is not None else None\n",
        "        if rating is not None:\n",
        "            rating = float(rating)\n",
        "            if rating > 3:\n",
        "                sentiment = 'positive'\n",
        "            elif rating < 2:\n",
        "                sentiment = 'negative'\n",
        "            else:\n",
        "                sentiment = 'neutral'\n",
        "            data.append((summary, text, category, sentiment))\n",
        "    df = pd.DataFrame(data, columns=['summary', 'text', 'category', 'sentiment'])\n",
        "    return df\n",
        "\n",
        "# Define file paths\n",
        "train_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/train.review'\n",
        "test_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/test.review'\n",
        "unlabeled_file_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled.review'\n",
        "\n",
        "# Parse XML files\n",
        "train_df = parse_xml_to_df(train_file_path)\n",
        "test_df = parse_xml_to_df(test_file_path)\n",
        "unlabeled_df = parse_xml_to_df(unlabeled_file_path)\n",
        "\n",
        "# Save to CSV\n",
        "train_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/train.csv'\n",
        "test_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/test.csv'\n",
        "unlabeled_csv_path = '/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled.csv'\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "unlabeled_df.to_csv(unlabeled_csv_path, index=False)\n",
        "\n",
        "print(\"Train DataFrame saved to CSV:\")\n",
        "print(train_df.head())\n",
        "print(\"Test DataFrame saved to CSV:\")\n",
        "print(test_df.head())\n",
        "print(\"Unlabeled DataFrame saved to CSV:\")\n",
        "print(unlabeled_df.head())\n",
        "\n",
        "# Verify columns\n",
        "print(train_df.columns)\n",
        "print(test_df.columns)\n",
        "print(unlabeled_df.columns)\n",
        "\n",
        "# Count positive, neutral, and negative sentiments in train and test data\n",
        "print(\"Train sentiment counts:\")\n",
        "print(train_df['sentiment'].value_counts())\n",
        "\n",
        "print(\"Test sentiment counts:\")\n",
        "print(test_df['sentiment'].value_counts())\n",
        "\n",
        "# Combine train and test data\n",
        "all_texts = pd.concat([train_df['text'], test_df['text']])\n",
        "all_sentiments = pd.concat([train_df['sentiment'], test_df['sentiment']])\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(all_texts)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(train_df['text'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(test_df['text'])\n",
        "X_unlabeled_seq = tokenizer.texts_to_sequences(unlabeled_df['text'])\n",
        "\n",
        "max_len = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "X_unlabeled_pad = pad_sequences(X_unlabeled_seq, maxlen=max_len)\n",
        "\n",
        "# Convert sentiments to numerical values\n",
        "sentiment_dict = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
        "y_train = train_df['sentiment'].map(sentiment_dict).values\n",
        "y_test = test_df['sentiment'].map(sentiment_dict).values\n",
        "\n",
        "# Build the model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=100, input_length=max_len))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(3, activation='softmax'))  # Change to 3 output units\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "# Predict on unlabeled data\n",
        "unlabeled_pred = model.predict(X_unlabeled_pad)\n",
        "unlabeled_pred_labels = ['positive' if p[0] == max(p) else 'neutral' if p[1] == max(p) else 'negative' for p in unlabeled_pred]\n",
        "\n",
        "unlabeled_df['predicted_sentiment'] = unlabeled_pred_labels\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "unlabeled_df.to_csv('/content/dataset/cls-acl10-unprocessed/en/dvd/unlabeled_with_predictions.csv', index=False)\n",
        "\n",
        "# Display the count of positive, neutral, and negative predictions\n",
        "print(\"Unlabeled predicted sentiment counts:\")\n",
        "print(unlabeled_df['predicted_sentiment'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdi9rYYaq4Xq",
        "outputId": "0c34dd33-87f9-4fd6-baf4-90c730ec11b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame saved to CSV:\n",
            "                                   summary  \\\n",
            "0                What! Ja WHO? Can't be!\\n   \n",
            "1          Not the music from this movie\\n   \n",
            "2  Stick To The Movie, THAT was a treat!\\n   \n",
            "3                           clapton suck\\n   \n",
            "4                              Dreadful!\\n   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  This is not what I expected from such a gifted...    music   neutral  \n",
            "1  This is not the music from the movie. This pur...    music  negative  \n",
            "2  Get's one star in appreciation of the technici...    music  negative  \n",
            "3  Layla is one of the most overrated songs of al...    music  negative  \n",
            "4  I don't understand the previous reviews - I fo...    music  negative  \n",
            "Test DataFrame saved to CSV:\n",
            "            summary                                               text  \\\n",
            "0  No Good At All\\n  Completely worthless! If you liked the film, g...   \n",
            "1  Recycled goods\\n  Having listened to Steven's previous albums, G...   \n",
            "2      TICKED OFF\\n  I bought this cd after hearing Tony on one of ...   \n",
            "3  Better Stoned?\\n  Um. I have nothing against bands that are \"mai...   \n",
            "4   Born to Croon\\n  Jeff Buckley sounds like what Marc Bolan would...   \n",
            "\n",
            "  category sentiment  \n",
            "0    music  negative  \n",
            "1    music  negative  \n",
            "2    music   neutral  \n",
            "3    music   neutral  \n",
            "4    music   neutral  \n",
            "Unlabeled DataFrame saved to CSV:\n",
            "                             summary  \\\n",
            "0                  What can I say?\\n   \n",
            "1  not quite ready for prime time.\\n   \n",
            "2                    Disapointment\\n   \n",
            "3                         ooo lord\\n   \n",
            "4              Boo them off stage.\\n   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  I've always held the philosophy you are what y...    music   neutral  \n",
            "1  someone get this band a producer and put them ...    music   neutral  \n",
            "2  Tihs Album is not all that good when it came o...    music   neutral  \n",
            "3  this industry is \"goin down\"  \\n \\n u call thi...    music  negative  \n",
            "4  I'm sorry but the guy below me doesn't know mu...    music  negative  \n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Train sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     569\n",
            "neutral      431\n",
            "Name: count, dtype: int64\n",
            "Test sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     535\n",
            "neutral      465\n",
            "Name: count, dtype: int64\n",
            "Epoch 1/5\n",
            "25/25 [==============================] - 14s 379ms/step - loss: 1.0496 - accuracy: 0.4863 - val_loss: 0.9823 - val_accuracy: 0.5375\n",
            "Epoch 2/5\n",
            "25/25 [==============================] - 11s 432ms/step - loss: 0.9681 - accuracy: 0.5606 - val_loss: 0.9297 - val_accuracy: 0.6025\n",
            "Epoch 3/5\n",
            "25/25 [==============================] - 8s 327ms/step - loss: 0.7432 - accuracy: 0.6587 - val_loss: 0.8099 - val_accuracy: 0.6475\n",
            "Epoch 4/5\n",
            "25/25 [==============================] - 10s 374ms/step - loss: 0.5026 - accuracy: 0.7744 - val_loss: 0.8613 - val_accuracy: 0.6675\n",
            "Epoch 5/5\n",
            "25/25 [==============================] - 10s 405ms/step - loss: 0.3320 - accuracy: 0.8712 - val_loss: 1.0215 - val_accuracy: 0.6625\n",
            "63/63 [==============================] - 6s 96ms/step - loss: 1.0962 - accuracy: 0.6230\n",
            "Test Accuracy: 0.6230000257492065\n",
            "789/789 [==============================] - 64s 80ms/step\n",
            "Unlabeled predicted sentiment counts:\n",
            "predicted_sentiment\n",
            "negative    12206\n",
            "positive     6859\n",
            "neutral      6155\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "# Function to parse XML files and return DataFrames\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for item in root.findall('item'):\n",
        "        summary = item.find('summary').text if item.find('summary') is not None else \"\"\n",
        "        text = item.find('text').text if item.find('text') is not None else \"\"\n",
        "        category = item.find('category').text if item.find('category') is not None else \"\"\n",
        "        rating = item.find('rating').text if item.find('rating') is not None else None\n",
        "        if rating is not None:\n",
        "            rating = float(rating)\n",
        "            if rating > 3:\n",
        "                sentiment = 'positive'\n",
        "            elif rating < 2:\n",
        "                sentiment = 'negative'\n",
        "            else:\n",
        "                sentiment = 'neutral'\n",
        "            data.append((summary, text, category, sentiment))\n",
        "    df = pd.DataFrame(data, columns=['summary', 'text', 'category', 'sentiment'])\n",
        "    return df\n",
        "\n",
        "# Define file paths for the \"music\" category\n",
        "train_file_path = '/content/dataset/cls-acl10-unprocessed/en/music/train.review'\n",
        "test_file_path = '/content/dataset/cls-acl10-unprocessed/en/music/test.review'\n",
        "unlabeled_file_path = '/content/dataset/cls-acl10-unprocessed/en/music/unlabeled.review'\n",
        "\n",
        "# Parse XML files\n",
        "train_df = parse_xml_to_df(train_file_path)\n",
        "test_df = parse_xml_to_df(test_file_path)\n",
        "unlabeled_df = parse_xml_to_df(unlabeled_file_path)\n",
        "\n",
        "# Save to CSV\n",
        "train_csv_path = '/content/dataset/cls-acl10-unprocessed/en/music/train.csv'\n",
        "test_csv_path = '/content/dataset/cls-acl10-unprocessed/en/music/test.csv'\n",
        "unlabeled_csv_path = '/content/dataset/cls-acl10-unprocessed/en/music/unlabeled.csv'\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "unlabeled_df.to_csv(unlabeled_csv_path, index=False)\n",
        "\n",
        "print(\"Train DataFrame saved to CSV:\")\n",
        "print(train_df.head())\n",
        "print(\"Test DataFrame saved to CSV:\")\n",
        "print(test_df.head())\n",
        "print(\"Unlabeled DataFrame saved to CSV:\")\n",
        "print(unlabeled_df.head())\n",
        "\n",
        "# Verify columns\n",
        "print(train_df.columns)\n",
        "print(test_df.columns)\n",
        "print(unlabeled_df.columns)\n",
        "\n",
        "# Count positive, neutral, and negative sentiments in train and test data\n",
        "print(\"Train sentiment counts:\")\n",
        "print(train_df['sentiment'].value_counts())\n",
        "\n",
        "print(\"Test sentiment counts:\")\n",
        "print(test_df['sentiment'].value_counts())\n",
        "\n",
        "# Combine train and test data\n",
        "all_texts = pd.concat([train_df['text'], test_df['text']])\n",
        "all_sentiments = pd.concat([train_df['sentiment'], test_df['sentiment']])\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(all_texts)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(train_df['text'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(test_df['text'])\n",
        "X_unlabeled_seq = tokenizer.texts_to_sequences(unlabeled_df['text'])\n",
        "\n",
        "max_len = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "X_unlabeled_pad = pad_sequences(X_unlabeled_seq, maxlen=max_len)\n",
        "\n",
        "# Convert sentiments to numerical values\n",
        "sentiment_dict = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
        "y_train = train_df['sentiment'].map(sentiment_dict).values\n",
        "y_test = test_df['sentiment'].map(sentiment_dict).values\n",
        "\n",
        "# Build the model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=100, input_length=max_len))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(3, activation='softmax'))  # Change to 3 output units\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "# Predict on unlabeled data\n",
        "unlabeled_pred = model.predict(X_unlabeled_pad)\n",
        "unlabeled_pred_labels = ['positive' if p[0] == max(p) else 'neutral' if p[1] == max(p) else 'negative' for p in unlabeled_pred]\n",
        "\n",
        "unlabeled_df['predicted_sentiment'] = unlabeled_pred_labels\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "unlabeled_df.to_csv('/content/dataset/cls-acl10-unprocessed/en/music/unlabeled_with_predictions.csv', index=False)\n",
        "\n",
        "# Display the count of positive, neutral, and negative predictions\n",
        "print(\"Unlabeled predicted sentiment counts:\")\n",
        "print(unlabeled_df['predicted_sentiment'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8X_xPyBsutJ",
        "outputId": "1b84b74e-08be-46f0-bde6-5a7af3086aff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0         Possibly the worst book I have ever read\\n   \n",
            "1             BORING WITH A TOTAL  LACK OF CLARITY\\n   \n",
            "2  Author sneaks in biblical misinterpretation, p...   \n",
            "3                                  Horrible Layout\\n   \n",
            "4                          Please be very careful!\\n   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  While I realize that the majority of people th...    books  negative  \n",
            "1  I had never read any of  Vernor Vinges books b...    books  negative  \n",
            "2  I got this as both a book and an audio file.  ...    books  negative  \n",
            "3  The content of this book is adequate, but the ...    books   neutral  \n",
            "4  This book can be very damaging if you approach...    books   neutral  \n",
            "Test DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0                         Good history, but.......\\n   \n",
            "1                                Refinement Needed\\n   \n",
            "2                                           A Bore\\n   \n",
            "3  What was country about the majority of the sto...   \n",
            "4                                 suks comepletely\\n   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  No doubt about it.  This book covers the histo...    books   neutral  \n",
            "1  There's a ton of paper in this book, overboard...    books   neutral  \n",
            "2  Each story has a different author...however th...    books  negative  \n",
            "3  A book full of heartwarming stories from count...    books   neutral  \n",
            "4  this joke book suks. if i can give it any star...    books  negative  \n",
            "Unlabeled DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0  I had a bad feeling about this!  And I was rig...   \n",
            "1  The book felt more like the author was forced ...   \n",
            "2             Reading shouldn't have to be a chore\\n   \n",
            "3                                         Revenge!\\n   \n",
            "4            Too Graphic-Too Long to get somewhere\\n   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  I was intrigued by the title, which supposedly...    books  negative  \n",
            "1  Why is it ever time you want something bad eno...    books   neutral  \n",
            "2  Once upon a time I was given a vanity-publishe...    books  negative  \n",
            "3  Let me see how many books can I write to preac...    books  negative  \n",
            "4  This book was so different from the usual NR s...    books   neutral  \n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Train sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     555\n",
            "neutral      445\n",
            "Name: count, dtype: int64\n",
            "Test sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     538\n",
            "neutral      462\n",
            "Name: count, dtype: int64\n",
            "Epoch 1/5\n",
            "25/25 [==============================] - 13s 391ms/step - loss: 1.0525 - accuracy: 0.4806 - val_loss: 0.9738 - val_accuracy: 0.5450\n",
            "Epoch 2/5\n",
            "25/25 [==============================] - 9s 336ms/step - loss: 0.8800 - accuracy: 0.5612 - val_loss: 0.8593 - val_accuracy: 0.6325\n",
            "Epoch 3/5\n",
            "25/25 [==============================] - 10s 404ms/step - loss: 0.6245 - accuracy: 0.6988 - val_loss: 0.8936 - val_accuracy: 0.6550\n",
            "Epoch 4/5\n",
            "25/25 [==============================] - 8s 307ms/step - loss: 0.4237 - accuracy: 0.8012 - val_loss: 1.0347 - val_accuracy: 0.5500\n",
            "Epoch 5/5\n",
            "25/25 [==============================] - 10s 408ms/step - loss: 0.2812 - accuracy: 0.8819 - val_loss: 1.4106 - val_accuracy: 0.6175\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 1.4717 - accuracy: 0.5970\n",
            "Test Accuracy: 0.597000002861023\n",
            "1563/1563 [==============================] - 123s 78ms/step\n",
            "Unlabeled predicted sentiment counts:\n",
            "predicted_sentiment\n",
            "negative    31037\n",
            "neutral     10457\n",
            "positive     8506\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "# Function to parse XML files and return DataFrames\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for item in root.findall('item'):\n",
        "        summary = item.find('summary').text if item.find('summary') is not None else \"\"\n",
        "        text = item.find('text').text if item.find('text') is not None else \"\"\n",
        "        category = item.find('category').text if item.find('category') is not None else \"\"\n",
        "        rating = item.find('rating').text if item.find('rating') is not None else None\n",
        "        if rating is not None:\n",
        "            rating = float(rating)\n",
        "            if rating > 3:\n",
        "                sentiment = 'positive'\n",
        "            elif rating < 2:\n",
        "                sentiment = 'negative'\n",
        "            else:\n",
        "                sentiment = 'neutral'\n",
        "            data.append((summary, text, category, sentiment))\n",
        "    df = pd.DataFrame(data, columns=['summary', 'text', 'category', 'sentiment'])\n",
        "    return df\n",
        "\n",
        "# Define file paths for the \"books\" category\n",
        "train_file_path = '/content/dataset/cls-acl10-unprocessed/en/books/train.review'\n",
        "test_file_path = '/content/dataset/cls-acl10-unprocessed/en/books/test.review'\n",
        "unlabeled_file_path = '/content/dataset/cls-acl10-unprocessed/en/books/unlabeled.review'\n",
        "\n",
        "# Parse XML files\n",
        "train_df = parse_xml_to_df(train_file_path)\n",
        "test_df = parse_xml_to_df(test_file_path)\n",
        "unlabeled_df = parse_xml_to_df(unlabeled_file_path)\n",
        "\n",
        "# Save to CSV\n",
        "train_csv_path = '/content/dataset/cls-acl10-unprocessed/en/books/train.csv'\n",
        "test_csv_path = '/content/dataset/cls-acl10-unprocessed/en/books/test.csv'\n",
        "unlabeled_csv_path = '/content/dataset/cls-acl10-unprocessed/en/books/unlabeled.csv'\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "unlabeled_df.to_csv(unlabeled_csv_path, index=False)\n",
        "\n",
        "print(\"Train DataFrame saved to CSV:\")\n",
        "print(train_df.head())\n",
        "print(\"Test DataFrame saved to CSV:\")\n",
        "print(test_df.head())\n",
        "print(\"Unlabeled DataFrame saved to CSV:\")\n",
        "print(unlabeled_df.head())\n",
        "\n",
        "# Verify columns\n",
        "print(train_df.columns)\n",
        "print(test_df.columns)\n",
        "print(unlabeled_df.columns)\n",
        "\n",
        "# Count positive, neutral, and negative sentiments in train and test data\n",
        "print(\"Train sentiment counts:\")\n",
        "print(train_df['sentiment'].value_counts())\n",
        "\n",
        "print(\"Test sentiment counts:\")\n",
        "print(test_df['sentiment'].value_counts())\n",
        "\n",
        "# Combine train and test data\n",
        "all_texts = pd.concat([train_df['text'], test_df['text']])\n",
        "all_sentiments = pd.concat([train_df['sentiment'], test_df['sentiment']])\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(all_texts)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(train_df['text'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(test_df['text'])\n",
        "X_unlabeled_seq = tokenizer.texts_to_sequences(unlabeled_df['text'])\n",
        "\n",
        "max_len = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "X_unlabeled_pad = pad_sequences(X_unlabeled_seq, maxlen=max_len)\n",
        "\n",
        "# Convert sentiments to numerical values\n",
        "sentiment_dict = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
        "y_train = train_df['sentiment'].map(sentiment_dict).values\n",
        "y_test = test_df['sentiment'].map(sentiment_dict).values\n",
        "\n",
        "# Build the model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=100, input_length=max_len))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(3, activation='softmax'))  # Change to 3 output units\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "# Predict on unlabeled data\n",
        "unlabeled_pred = model.predict(X_unlabeled_pad)\n",
        "unlabeled_pred_labels = ['positive' if p[0] == max(p) else 'neutral' if p[1] == max(p) else 'negative' for p in unlabeled_pred]\n",
        "\n",
        "unlabeled_df['predicted_sentiment'] = unlabeled_pred_labels\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "unlabeled_df.to_csv('/content/dataset/cls-acl10-unprocessed/en/books/unlabeled_with_predictions.csv', index=False)\n",
        "\n",
        "# Display the count of positive, neutral, and negative predictions\n",
        "print(\"Unlabeled predicted sentiment counts:\")\n",
        "print(unlabeled_df['predicted_sentiment'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2c6RGrWtxuK",
        "outputId": "047bc97c-86c0-4cd6-9899-1ea6a94b7247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame saved to CSV:\n",
            "                                  summary  \\\n",
            "0                           Selenas Album   \n",
            "1  gutes Lied,aber die Interpretation ...   \n",
            "2                           Frischer Wind   \n",
            "3                Nyze was ist passiert???   \n",
            "4         ccn 2 Entäuscht auf gazer linie   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  Auch ich bin der Meinung, dass Selena Gomez li...    Musik  negative  \n",
            "1  Dies ist meine erste Rezension, aber da ich di...    Musik   neutral  \n",
            "2  Ich stiess per Zufall im Internet auf dieses A...    Musik  positive  \n",
            "3  Ich bin ja ein großer Ersguterjunge-Fan und de...    Musik  negative  \n",
            "4  Bin total entäuscht von ccn 2 das hätten die l...    Musik  negative  \n",
            "Test DataFrame saved to CSV:\n",
            "                        summary  \\\n",
            "0  Timbaland's neue Schützlinge   \n",
            "1        hmmmmm trio ohne geist   \n",
            "2     Kitty Kat ist der Shit...   \n",
            "3     Gekauft und Zurückgegeben   \n",
            "4   Lily Allen - Alright, Still   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  Ryan Tedder, Zach Filkins, Eddie Fisher, Brent...    Musik  positive  \n",
            "1  also ihr leute da draussen wat auch imma die d...    Musik  negative  \n",
            "2  .... wie sie ja selbst auch zu wissen scheint ...    Musik  positive  \n",
            "3  Das ist ja wohl Verarsche oder? Ich hab Bushid...    Musik   neutral  \n",
            "4  Lily Allen dürfte wohl mittlerweile jeder kenn...    Musik   neutral  \n",
            "Unlabeled DataFrame saved to CSV:\n",
            "                       summary  \\\n",
            "0        Schöne rockige Stücke   \n",
            "1   Gute Musik und Super Video   \n",
            "2                Eine super CD   \n",
            "3    Ein grandioser Soundtrack   \n",
            "4  Get Lucky von Mark Knopfler   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  Ich bin der Meinung, dass der Soundtrack sehr ...    Musik  positive  \n",
            "1  Echt ein super Musik Mix aus popigen und ruhig...    Musik  positive  \n",
            "2  Es ist alles so gewesen wie ich es mir vorgest...    Musik  positive  \n",
            "3  Bevor ich zum Soundtrack von ODST komme, muss ...    Musik  positive  \n",
            "4  Bin Knopfler Fan, daher ein Muß für mich,\\n ge...    Musik  positive  \n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Train sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     560\n",
            "neutral      440\n",
            "Name: count, dtype: int64\n",
            "Test sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     572\n",
            "neutral      428\n",
            "Name: count, dtype: int64\n",
            "Epoch 1/5\n",
            "25/25 [==============================] - 13s 382ms/step - loss: 1.0496 - accuracy: 0.4944 - val_loss: 1.0424 - val_accuracy: 0.4725\n",
            "Epoch 2/5\n",
            "25/25 [==============================] - 9s 345ms/step - loss: 0.9022 - accuracy: 0.5519 - val_loss: 0.9166 - val_accuracy: 0.5125\n",
            "Epoch 3/5\n",
            "25/25 [==============================] - 10s 400ms/step - loss: 0.6488 - accuracy: 0.7163 - val_loss: 0.8713 - val_accuracy: 0.5975\n",
            "Epoch 4/5\n",
            "25/25 [==============================] - 10s 390ms/step - loss: 0.4323 - accuracy: 0.8169 - val_loss: 1.0174 - val_accuracy: 0.5650\n",
            "Epoch 5/5\n",
            "25/25 [==============================] - 9s 362ms/step - loss: 0.2209 - accuracy: 0.9275 - val_loss: 1.2586 - val_accuracy: 0.5625\n",
            "63/63 [==============================] - 4s 64ms/step - loss: 1.2805 - accuracy: 0.5855\n",
            "Test Accuracy: 0.5855000019073486\n",
            "1887/1887 [==============================] - 147s 77ms/step\n",
            "Unlabeled predicted sentiment counts:\n",
            "predicted_sentiment\n",
            "negative    30961\n",
            "neutral     14795\n",
            "positive    14626\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Function to parse XML files and return DataFrames\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for item in root.findall('item'):\n",
        "        summary = item.find('summary').text if item.find('summary') is not None else \"\"\n",
        "        text = item.find('text').text if item.find('text') is not None else \"\"\n",
        "        category = item.find('category').text if item.find('category') is not None else \"\"\n",
        "        rating = item.find('rating').text if item.find('rating') is not None else None\n",
        "        if rating is not None:\n",
        "            rating = float(rating)\n",
        "            if rating > 3:\n",
        "                sentiment = 'positive'\n",
        "            elif rating < 2:\n",
        "                sentiment = 'negative'\n",
        "            else:\n",
        "                sentiment = 'neutral'\n",
        "            data.append((summary, text, category, sentiment))\n",
        "    df = pd.DataFrame(data, columns=['summary', 'text', 'category', 'sentiment'])\n",
        "    return df\n",
        "\n",
        "# Define file paths for the \"music\" category\n",
        "train_file_path = '/content/dataset/cls-acl10-unprocessed/de/music/train.review'\n",
        "test_file_path = '/content/dataset/cls-acl10-unprocessed/de/music/test.review'\n",
        "unlabeled_file_path = '/content/dataset/cls-acl10-unprocessed/de/music/unlabeled.review'\n",
        "\n",
        "# Parse XML files\n",
        "train_df = parse_xml_to_df(train_file_path)\n",
        "test_df = parse_xml_to_df(test_file_path)\n",
        "unlabeled_df = parse_xml_to_df(unlabeled_file_path)\n",
        "\n",
        "# Save to CSV\n",
        "train_csv_path = '/content/dataset/cls-acl10-unprocessed/de/music/train.csv'\n",
        "test_csv_path = '/content/dataset/cls-acl10-unprocessed/de/music/test.csv'\n",
        "unlabeled_csv_path = '/content/dataset/cls-acl10-unprocessed/de/music/unlabeled.csv'\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "unlabeled_df.to_csv(unlabeled_csv_path, index=False)\n",
        "\n",
        "print(\"Train DataFrame saved to CSV:\")\n",
        "print(train_df.head())\n",
        "print(\"Test DataFrame saved to CSV:\")\n",
        "print(test_df.head())\n",
        "print(\"Unlabeled DataFrame saved to CSV:\")\n",
        "print(unlabeled_df.head())\n",
        "\n",
        "# Verify columns\n",
        "print(train_df.columns)\n",
        "print(test_df.columns)\n",
        "print(unlabeled_df.columns)\n",
        "\n",
        "# Count positive, neutral, and negative sentiments in train and test data\n",
        "print(\"Train sentiment counts:\")\n",
        "print(train_df['sentiment'].value_counts())\n",
        "print(\"Test sentiment counts:\")\n",
        "print(test_df['sentiment'].value_counts())\n",
        "\n",
        "# Combine train and test data\n",
        "all_texts = pd.concat([train_df['text'], test_df['text']])\n",
        "all_sentiments = pd.concat([train_df['sentiment'], test_df['sentiment']])\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(all_texts)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(train_df['text'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(test_df['text'])\n",
        "\n",
        "# Ensure that the unlabeled data has valid text entries\n",
        "unlabeled_df = unlabeled_df[unlabeled_df['text'].notnull() & (unlabeled_df['text'] != '')]\n",
        "X_unlabeled_seq = tokenizer.texts_to_sequences(unlabeled_df['text'])\n",
        "\n",
        "max_len = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "X_unlabeled_pad = pad_sequences(X_unlabeled_seq, maxlen=max_len)\n",
        "\n",
        "# Convert sentiments to numerical values\n",
        "sentiment_dict = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
        "y_train = train_df['sentiment'].map(sentiment_dict).values\n",
        "y_test = test_df['sentiment'].map(sentiment_dict).values\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=100, input_length=max_len))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(3, activation='softmax'))  # Change to 3 output units\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "# Predict on unlabeled data\n",
        "unlabeled_pred = model.predict(X_unlabeled_pad)\n",
        "unlabeled_pred_labels = ['positive' if p[0] == max(p) else 'neutral' if p[1] == max(p) else 'negative' for p in unlabeled_pred]\n",
        "\n",
        "unlabeled_df['predicted_sentiment'] = unlabeled_pred_labels\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "unlabeled_df.to_csv('/content/dataset/cls-acl10-unprocessed/de/music/unlabeled_with_predictions.csv', index=False)\n",
        "\n",
        "# Display the count of positive, neutral, and negative predictions\n",
        "print(\"Unlabeled predicted sentiment counts:\")\n",
        "print(unlabeled_df['predicted_sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv7DGl1k_Ldu",
        "outputId": "7befe164-4890-49f0-e057-b7fcd78426d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Books Train DataFrame saved to CSV:\n",
            "                                   summary  \\\n",
            "0                    Fensterputzen im Kopf   \n",
            "1          modernes Märchen zum schmunzeln   \n",
            "2                  langweilig statt lustig   \n",
            "3  Ein unordentliches und ärgerliches Buch   \n",
            "4                                 Sappalot   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  \"Zur Beruhigung flüstert sie sich manchmal ein...   Bücher  positive  \n",
            "1  Ok, ich gebe zu, die Story ist nicht gerade au...   Bücher  positive  \n",
            "2  Von Spass kann hier wirklich keine Rede sein. ...   Bücher  negative  \n",
            "3  Der Germanist Precht dilettiert in diesem Buch...   Bücher  negative  \n",
            "4  Ich möchte mir nicht anmaßen über Schreibstil ...   Bücher  positive  \n",
            "Books Test DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0  Gutes Einstand - Bodenständigkeit aus Altbaiern;)   \n",
            "1                       Es musste ja so kommen......   \n",
            "2              Deutschland, ein kurzes, langes Glück   \n",
            "3  Ein kleines bisschen Märchenwelt in unserer Ze...   \n",
            "4  Ergreifende Geschichte aus dunkler Zeit - Sehr...   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  Wichtig sind für einen guten Krimi meiner Mein...   Bücher  positive  \n",
            "1  Probably sponsored by the Washington D.C. Boar...   Bücher   neutral  \n",
            "2  Zuallererst: Die Geschichte ist vordergründig ...   Bücher  positive  \n",
            "3  So endgültig das Ende von \"Gut gegen Nordwind\"...   Bücher  positive  \n",
            "4  Gerade eben habe ich die Lektüre dieses ungewö...   Bücher  positive  \n",
            "Books Unlabeled DataFrame saved to CSV:\n",
            "              summary                                               text  \\\n",
            "0          Vorbehalte  Jeder Bericht über eine Leseerfahrung kann nur...   \n",
            "1    ..enttäuscht....  bin ich vonLIMIT.\\n Schätzing hat sich trotz d...   \n",
            "2           Na ja....  Als absoluter Fan von \"der Schwarm\" mußte natü...   \n",
            "3  Überfrachtet banal  Es ist nicht so, das Frank Schätzing nicht sch...   \n",
            "4          Schwätzing  Ich glaube der Mann hat sich das Erfolgskonzep...   \n",
            "\n",
            "  category sentiment  \n",
            "0   Bücher   neutral  \n",
            "1   Bücher  negative  \n",
            "2   Bücher   neutral  \n",
            "3   Bücher   neutral  \n",
            "4   Bücher   neutral  \n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Books Train sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     543\n",
            "neutral      457\n",
            "Name: count, dtype: int64\n",
            "Books Test sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     551\n",
            "neutral      449\n",
            "Name: count, dtype: int64\n",
            "Dvd Train DataFrame saved to CSV:\n",
            "                                         summary  \\\n",
            "0                 Der Preis ist eine Frechheit!    \n",
            "1                       Wertung des Films selbst   \n",
            "2  Produktionsfehler und somit nicht vollständig   \n",
            "3                              Wolverine is BACK   \n",
            "4                           Zu schlecht bewertet   \n",
            "\n",
            "                                                text           category  \\\n",
            "0  Eins muss man ganz klar sagen. Two and a half ...  DVD &amp; Blu-ray   \n",
            "1  ich möchte in meiner Rezession nicht auf die t...  DVD &amp; Blu-ray   \n",
            "2  Hallo,\\n auch bei meiner DVD Box ist der berei...  DVD &amp; Blu-ray   \n",
            "3  Der Film ist im Grunde wie alle Teile der X-Me...  DVD &amp; Blu-ray   \n",
            "4  Also Filme und Bücher sind ja bekanntlich Ansi...  DVD &amp; Blu-ray   \n",
            "\n",
            "  sentiment  \n",
            "0  negative  \n",
            "1  negative  \n",
            "2  negative  \n",
            "3  positive  \n",
            "4  positive  \n",
            "Dvd Test DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0  Insgesamt enttäuschend und nur bedingt Kindern...   \n",
            "1                             Unterirdisch schlecht.   \n",
            "2                                    Voll daneben...   \n",
            "3                            Drama und keine Komödie   \n",
            "4       Sehr gut in Szene gesetzter Agenten-Thriller   \n",
            "\n",
            "                                                text           category  \\\n",
            "0  Begeistert von IceAge2 haben meine Kinder (4 +...  DVD &amp; Blu-ray   \n",
            "1  Selten einen so \"grottig\" schlechten Film gese...  DVD &amp; Blu-ray   \n",
            "2  Wow. Selten hat jemand so daneben geschossen w...  DVD &amp; Blu-ray   \n",
            "3  Es mag Leute geben, den dieser Film langatmig ...  DVD &amp; Blu-ray   \n",
            "4  Endlich (wieder) einmal haben es die Macher ei...  DVD &amp; Blu-ray   \n",
            "\n",
            "  sentiment  \n",
            "0   neutral  \n",
            "1  negative  \n",
            "2   neutral  \n",
            "3  positive  \n",
            "4  positive  \n",
            "Dvd Unlabeled DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0  \"...da ist eben ein nackter Mann in unsere Sch...   \n",
            "1         Nicht nur für Blödbommel und Zipfel, Häää!   \n",
            "2           Greift lieber zum Buch oder zum Hörbuch!   \n",
            "3  nicht ansehen, wenn man das buch kennt und lie...   \n",
            "4                          Leider schlecht umgesetzt   \n",
            "\n",
            "                                                text           category  \\\n",
            "0  X MEN ORIGINS : WOLVERINE präsentiert uns die ...  DVD &amp; Blu-ray   \n",
            "1  Komme gerade aus dem Kino. Großartiger Film.\\n...  DVD &amp; Blu-ray   \n",
            "2  Für mich und meine Lebensgefährtin war der Fil...  DVD &amp; Blu-ray   \n",
            "3  Ich finde das der Film an sich schon sehenswer...  DVD &amp; Blu-ray   \n",
            "4  Illuminati gehört für  mich ganz klar zu eines...  DVD &amp; Blu-ray   \n",
            "\n",
            "  sentiment  \n",
            "0   neutral  \n",
            "1  positive  \n",
            "2   neutral  \n",
            "3   neutral  \n",
            "4   neutral  \n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Dvd Train sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     592\n",
            "neutral      408\n",
            "Name: count, dtype: int64\n",
            "Dvd Test sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     566\n",
            "neutral      434\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Function to parse XML files and return DataFrames\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for item in root.findall('item'):\n",
        "        summary = item.find('summary').text if item.find('summary') is not None else \"\"\n",
        "        text = item.find('text').text if item.find('text') is not None else \"\"\n",
        "        category = item.find('category').text if item.find('category') is not None else \"\"\n",
        "        rating = item.find('rating').text if item.find('rating') is not None else None\n",
        "        if rating is not None:\n",
        "            rating = float(rating)\n",
        "            if rating > 3:\n",
        "                sentiment = 'positive'\n",
        "            elif rating < 2:\n",
        "                sentiment = 'negative'\n",
        "            else:\n",
        "                sentiment = 'neutral'\n",
        "            data.append((summary, text, category, sentiment))\n",
        "    df = pd.DataFrame(data, columns=['summary', 'text', 'category', 'sentiment'])\n",
        "    return df\n",
        "\n",
        "# Function to process category files\n",
        "def process_category(language, category):\n",
        "    # Define file paths for the category\n",
        "    train_file_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/train.review'\n",
        "    test_file_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/test.review'\n",
        "    unlabeled_file_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/unlabeled.review'\n",
        "\n",
        "    # Parse XML files\n",
        "    train_df = parse_xml_to_df(train_file_path)\n",
        "    test_df = parse_xml_to_df(test_file_path)\n",
        "    unlabeled_df = parse_xml_to_df(unlabeled_file_path)\n",
        "\n",
        "    # Save to CSV\n",
        "    train_csv_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/train.csv'\n",
        "    test_csv_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/test.csv'\n",
        "    unlabeled_csv_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/unlabeled.csv'\n",
        "\n",
        "    train_df.to_csv(train_csv_path, index=False)\n",
        "    test_df.to_csv(test_csv_path, index=False)\n",
        "    unlabeled_df.to_csv(unlabeled_csv_path, index=False)\n",
        "\n",
        "    print(f\"{category.capitalize()} Train DataFrame saved to CSV:\")\n",
        "    print(train_df.head())\n",
        "    print(f\"{category.capitalize()} Test DataFrame saved to CSV:\")\n",
        "    print(test_df.head())\n",
        "    print(f\"{category.capitalize()} Unlabeled DataFrame saved to CSV:\")\n",
        "    print(unlabeled_df.head())\n",
        "\n",
        "    # Verify columns\n",
        "    print(train_df.columns)\n",
        "    print(test_df.columns)\n",
        "    print(unlabeled_df.columns)\n",
        "\n",
        "    # Count positive, neutral, and negative sentiments in train and test data\n",
        "    print(f\"{category.capitalize()} Train sentiment counts:\")\n",
        "    print(train_df['sentiment'].value_counts())\n",
        "    print(f\"{category.capitalize()} Test sentiment counts:\")\n",
        "    print(test_df['sentiment'].value_counts())\n",
        "\n",
        "# Process both books and dvd categories for German language\n",
        "process_category('de', 'books')\n",
        "process_category('de', 'dvd')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq0XAtxk_zKi",
        "outputId": "fdddbfe3-3958-4a1e-b527-f20c5956b205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Japanese datasets...\n",
            "Books Train DataFrame saved to CSV:\n",
            "                               summary  \\\n",
            "0  これはトリビュート漫画の作者を知ってるか知らないかで評価が分かれますね   \n",
            "1                初心者の方にあれば心強いアイテムかもです。   \n",
            "2                              作りなおせ!!   \n",
            "3                         宣伝文句に釣られた怠け者   \n",
            "4                          肝心なところが抜けてる   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  あずまんが10周年記念で出たこの大阪万博。\\n 前半はあずまんがグッズ等の資料が載っていて後...        本  positive  \n",
            "1  付録の雑誌が欲しかったのでそれ狙いに買いましたが\\n 剛ラオの情報とかも記載されてるので非常...        本  positive  \n",
            "2  前半の資料には☆5個  後半の、誰一人として知らん作家が描いた漫画には☆0個  トータル☆1...        本  negative  \n",
            "3  要は短い英会話のヒアリング練習教材。\\n ステレオで聴くと、話し手が歩き回っているような臨場...        本   neutral  \n",
            "4  見るところは大体錬金になってきそうですが、最強装備を目指す勇者たちにとっては肝心なところが抜...        本   neutral  \n",
            "Books Test DataFrame saved to CSV:\n",
            "           summary                                               text  \\\n",
            "0      中国人が義を重んじる？  副島さんの著書のファンだったので期待したが\\n 中国人を全くわかっていないというか接触\\n ...   \n",
            "1  軽薄な内容を軽薄に書いた変な本  バブルっぽい雰囲気の中ならそれほど違和感がないだろうけど，現時点では「何で今の時期に？」と思...   \n",
            "2       勇気を与えてくれる本  よびりんさん（市川善彦氏）は、人をやる気にさせる天才です！\\n そのブログをまとめた本書はど...   \n",
            "3          まずは土台から  個人的に効果アリだと思います、この小顔体操。\\n 自分の顔って、左右対称じゃないなぁと思って...   \n",
            "4          少女観察まんが  女子中学生のだらだらとした日常を切り取った萌えマンガ。\\n 百合と言い切るには味付けが薄いで...   \n",
            "\n",
            "  category sentiment  \n",
            "0        本  negative  \n",
            "1        本   neutral  \n",
            "2        本  positive  \n",
            "3        本  positive  \n",
            "4        本  positive  \n",
            "Books Unlabeled DataFrame saved to CSV:\n",
            "                  summary                                               text  \\\n",
            "0               これは絶対･･･！  店頭で本だけを見た時は、「またエコバックみたいな\\n ペラペラバックでしょ〜？」と思っちゃい...   \n",
            "1                 体重が落ちた！  ゴムバンド付きにひかれて、購入。\\n 私は１週間続けて、４キロ体重が減りました！\\n 太もも...   \n",
            "2            まったく普通の内容でした  バンド付で筆者の真摯な姿勢は伝わってきましたが内容が私にとっては本当に\\n 普通に感じました...   \n",
            "3              全身がだるくなります  人気商品だったので割高ですが中古品を買いました。\\n さっそくやってみたのですが・・・\\n ...   \n",
            "4  バンドはほんとに効果出るね、でも届くの遅すぎ  金スマで買った口です。\\n バンドが欲しくて買ったのだけど、意外にも（？）イラストがかわいく...   \n",
            "\n",
            "  category sentiment  \n",
            "0        本  positive  \n",
            "1        本  positive  \n",
            "2        本   neutral  \n",
            "3        本  negative  \n",
            "4        本   neutral  \n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Books Train sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "neutral      523\n",
            "negative     477\n",
            "Name: count, dtype: int64\n",
            "Books Test sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "neutral      502\n",
            "negative     498\n",
            "Name: count, dtype: int64\n",
            "Dvd Train DataFrame saved to CSV:\n",
            "                                     summary  \\\n",
            "0                                     観客は傍観者   \n",
            "1                                      映像が残念   \n",
            "2                                 いい加減にして欲しい   \n",
            "3  白のダッジ･チャレンジャーと言えば、『バニシング･ポイント』のコワルスキーですね。   \n",
            "4                                再熱しちゃって思わず…   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  前作の、神秘に包まれた仮定と息を呑む謎解きの過程、意外な人物交錯を期待すると、とんでもない目...      DVD  negative  \n",
            "1  念願のＤＶＤ発売でドキドキ、ワクワクと期待して一曲目を再生したところ、酔いそうになりました。...      DVD   neutral  \n",
            "2  まったく。こんなのは止めて欲しい。毎週毎週、つまらないストーリーに、ウンザリするギャグ。ふざ...      DVD  positive  \n",
            "3  子供の頃『バニシング･ポイント』を映画館で観て衝撃を受けた者としては、白のダッジ･チャレンジ...      DVD  positive  \n",
            "4  買う予定なかったのに、最近冷めていた筈の熱が復活しちゃいまして…\\n なので、お金ないのに、...      DVD  positive  \n",
            "Dvd Test DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0                                    感動のカウントダウンコンサート   \n",
            "1                                      もう少しプライドと自身作を   \n",
            "2                                         嵐初心者でございます   \n",
            "3                                        むしろファン向けでよい   \n",
            "4  This is the Miracle.  The Moon is Walking.・・・現...   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  ディスク３の京セラドームでのカウントダウンコンサートが特に良かったです。\\n 地元で年越しの...      DVD  positive  \n",
            "1  今や商業化販売の第一人者の この人達。数だけ売ってますが内容と金額に比例していると思っている...      DVD  negative  \n",
            "2  たまたま嵐の番組を見るようになり、遅まきながら「嵐、いいなぁ」と思うようになりました。\\n ...      DVD  positive  \n",
            "3  ベスト版を引っさげてなので，有名な曲ばかりだと思い込んで買うのをためらってました。\\n しか...      DVD  positive  \n",
            "4  １９８８年の公開以来、２０年以上たった今、初めてこの映画を見た。\\n 「ＭＡＮ　ＩＮ　ＴＨＥ...      DVD  positive  \n",
            "Dvd Unlabeled DataFrame saved to CSV:\n",
            "                   summary                                               text  \\\n",
            "0         前監督らのツケが大いに回ってきた  あのやり方じゃドラコの苦労の意味が全くない\\n ただデスイーターが試験的にホグワーツにこっそ...   \n",
            "1  何もかもか駆け足過ぎて中途半端な感は否めぬ作品  ｼﾘｰｽﾞも回が進むほど顕著になっていた物語の希薄感(長い原作をまとめる苦労感)が本作も顕著...   \n",
            "2         ストーリーの薄さに少々疲れ気味…  ハリーポッターシリーズは１作目から全て観ています。\\n 各２回ずつは観ていますが、このシリー...   \n",
            "3                  忍野が影の主役  全３話を通してみて一番印象に残っているのは、忍野の存在です。\\n 　作品中で唯一の大人ですが...   \n",
            "4                  ほんとに無念…  ストーリーやキャラ同士の掛け合いは素晴らしいのに、シャフトの癖のある紙芝居演出が全てを台無し...   \n",
            "\n",
            "  category sentiment  \n",
            "0      DVD  negative  \n",
            "1      DVD   neutral  \n",
            "2      DVD   neutral  \n",
            "3      DVD  positive  \n",
            "4      DVD   neutral  \n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Dvd Train sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "neutral      530\n",
            "negative     470\n",
            "Name: count, dtype: int64\n",
            "Dvd Test sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     532\n",
            "neutral      468\n",
            "Name: count, dtype: int64\n",
            "Music Train DataFrame saved to CSV:\n",
            "               summary                                               text  \\\n",
            "0           何だかんだ言っても…  相変わらず批判凄いですね (・_・、) まぁしょうがないですね。 これだけ売れてたら… 1章...   \n",
            "1  偶然に聞いてしまいましたが・・・・・。  この作品自体は見たこと無かったんですが、友人のカーステに入ってたの聞きまして、一度に全種買い...   \n",
            "2              うーん....  パーフェクトイャーでベスト3枚という事で最初のキャッチーを購入したのですがイマイチだった為、...   \n",
            "3                ジャイアン  たしかに絢香の歌い方って自己満足なんですよね\\n 押し付けがましい。\\n 自分さえ気持ちよけ...   \n",
            "4            期待してたけど。。  私は荒削りな１ｓｔの方が好きです。\\n ２ｎｄは衝撃がなかった！\\n よりポップになりすぎて...   \n",
            "\n",
            "  category sentiment  \n",
            "0   ミュージック  negative  \n",
            "1   ミュージック  positive  \n",
            "2   ミュージック   neutral  \n",
            "3   ミュージック   neutral  \n",
            "4   ミュージック   neutral  \n",
            "Music Test DataFrame saved to CSV:\n",
            "          summary                                               text category  \\\n",
            "0      素晴らしい出来です!  オールシングル曲が収録されている「夢幻」です。最近は奈々さんの新曲をチェックしていなかったの...   ミュージック   \n",
            "1  唯ちゃん風にバッサリいうと…  「なんていうか…すごく言葉にしにくいんだけど…」「…あんまりうまくないですね！」あーほんとに...   ミュージック   \n",
            "2        またCD出すの?  女優業一本で頑張ってほしいです。コワイ童話、悪いオンナ等の役をやってた頃はすごく良かった。 ...   ミュージック   \n",
            "3       まあよかったです!  注文する前からスタジオ音源だということを聞いていたのでそこまでがっかりはしませんでしたが や...   ミュージック   \n",
            "4       かなりおススメです  あまり音楽にこだわる方じゃなく、\\n このＣＤも人に勧められて、何となく聴きはじめたのですが...   ミュージック   \n",
            "\n",
            "  sentiment  \n",
            "0  positive  \n",
            "1   neutral  \n",
            "2  negative  \n",
            "3  positive  \n",
            "4  positive  \n",
            "Music Unlabeled DataFrame saved to CSV:\n",
            "                        summary  \\\n",
            "0                 ロンドン公演のセットリスト   \n",
            "1                   次は視聴してから買おう   \n",
            "2                         大人しいね   \n",
            "3                 スタンダードポップアルバム   \n",
            "4  DISC2だけでも、詩の朗読だけでも同じ値段を払います！   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  初日に映画観てきました…リハーサルとは思えないほどに歌もダンスもクオリティが高くて本当に素晴...   ミュージック  positive  \n",
            "1  デビュー当時からのファンで、毎回心待ちにしてアルバムを買うのですが、先回に続き今回も”ん〜”...   ミュージック   neutral  \n",
            "2  少数派かもしれないがわたしの評価は低い。  聞いてみて大人しいなあーと思った。 アルバムの前...   ミュージック   neutral  \n",
            "3  「雫」を聴いて気になり、「虹のレシピ」で決意を感じ、「ゴールデンタイムラバー」で勝ちを確信。...   ミュージック  positive  \n",
            "4  DISC1はオリジナルアルバムマスター音源、\\n DISC2は未発表デモ音源及びマイケルによ...   ミュージック  positive  \n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Music Train sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "neutral      528\n",
            "negative     472\n",
            "Name: count, dtype: int64\n",
            "Music Test sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     503\n",
            "neutral      497\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Processing French datasets...\n",
            "Books Train DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0               A quand une vraie (bonne) histoire ?   \n",
            "1                                 Bof, du commercial   \n",
            "2          Si c'est un homme nous laisse sans voix !   \n",
            "3      En plus, il ne se prend pas pour un témoin...   \n",
            "4  Questions ciblées pour maigrir mais bilan payant.   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  Bilan plus que mitigé pour cet album fourre-to...   Livres   neutral  \n",
            "1  Quel déception, si cher pour cela.\\n Après la ...   Livres  negative  \n",
            "2  On croit bien évidemment tout savoir sur l'hor...   Livres  positive  \n",
            "3  \"Nous qui avons survécu, disait Primo Levi, no...   Livres  positive  \n",
            "4  Les questions sont ciblées et il faut avoir le...   Livres   neutral  \n",
            "Books Test DataFrame saved to CSV:\n",
            "                                summary  \\\n",
            "0  UN LIVRE FORT POUR PERSONNES FAIBLES   \n",
            "1     super recettes faciles à réaliser   \n",
            "2                       Zozo est arrivé   \n",
            "3                  Si simple et si fort   \n",
            "4                   Le coeur des hommes   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  J'ai lu ce livre car dans ma ville, tout le mo...   Livres  positive  \n",
            "1  Recettes appréciées de toute la famille (petit...   Livres  positive  \n",
            "2  Beigbeder se drape de mystère. Il pose avec de...   Livres  negative  \n",
            "3  Un petit livre si facile à lire et si puissant...   Livres  positive  \n",
            "4  Saint-Exupéry réalise à travers l'histoire du ...   Livres  positive  \n",
            "Books Unlabeled DataFrame saved to CSV:\n",
            "                             summary  \\\n",
            "0  Très loin des éloges médiatiques!   \n",
            "1           des phrases trop longues   \n",
            "2                     super ennuyeux   \n",
            "3                          bouillie!   \n",
            "4     UNE LECTRICE QUI NE L'A PAS LU   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  Des phrases qui n'en finissent pas, \"le mieux ...   Livres   neutral  \n",
            "1  Je trouve cet ouvrage inachevé. Il n'a pas été...   Livres   neutral  \n",
            "2  Alors là, je lui donne la palme de l'ennui, au...   Livres  negative  \n",
            "3  ce sont trois nouvelles rassemblées et pas un ...   Livres  negative  \n",
            "4  Les commentaires déjà saisis sont pour le moin...   Livres  negative  \n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Books Train sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     519\n",
            "neutral      481\n",
            "Name: count, dtype: int64\n",
            "Books Test sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     532\n",
            "neutral      468\n",
            "Name: count, dtype: int64\n",
            "Dvd Train DataFrame saved to CSV:\n",
            "                                          summary  \\\n",
            "0  de Charybe en ...Scylla  ( Attention Spoiler )   \n",
            "1                               Œuvre  magnifique   \n",
            "2                             TOURNEZ VOTRE NAVET   \n",
            "3                      Mais où s'arrêteront-ils ?   \n",
            "4                 désolée mais ce sera sans moi !   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  Prison Break, c'est un peu l'histoire d'un pét...      DVD  negative  \n",
            "1  Rare son les Opéras qui respecte  la mise en s...      DVD  positive  \n",
            "2  Voici pour cela une  bonne vieille recette qui...      DVD  negative  \n",
            "3  Il va des séries comme des groupes de musique....      DVD  positive  \n",
            "4  Devant la pluie d'éloges pour cette série, j'a...      DVD  negative  \n",
            "Dvd Test DataFrame saved to CSV:\n",
            "                                        summary  \\\n",
            "0                                 quel naufrage   \n",
            "1                         brouillon et bruiyant   \n",
            "2                        Vraiment vraiment bof!   \n",
            "3               Des origines sans grand intérêt   \n",
            "4  un champion de babyfoot en champions' league   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  Alors que les premiers X-men avaient l'affecti...      DVD   neutral  \n",
            "1  on attendait bien plus sur cette génèse; les e...      DVD   neutral  \n",
            "2  Une histoire qui s'éloigne du livre, des scène...      DVD   neutral  \n",
            "3  Wolverine est de retour, sans les X-Men et por...      DVD   neutral  \n",
            "4  Grand fan de la période \"épisodes courts et dr...      DVD   neutral  \n",
            "Dvd Unlabeled DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0                             Un must dans le genre.   \n",
            "1                             Excellent documentaire   \n",
            "2                    Des origines sans grand intérêt   \n",
            "3                        un navet pur adamantium....   \n",
            "4  quelle douche froide, après la ferveur de l'at...   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  Vous entendrez partout que les images de ce do...      DVD  positive  \n",
            "1  Excellent documentaire offrant une véritable v...      DVD  positive  \n",
            "2  Wolverine est de retour, sans les X-Men et por...      DVD   neutral  \n",
            "3  .. Non ,non , non ! ; marre de ces adaptations...      DVD  negative  \n",
            "4  Nous nous étions habitués à l'image fidèle du ...      DVD  negative  \n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Dvd Train sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     607\n",
            "neutral      393\n",
            "Name: count, dtype: int64\n",
            "Dvd Test sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     558\n",
            "neutral      442\n",
            "Name: count, dtype: int64\n",
            "Music Train DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0  Quelle déception! Quelle soif de fric de l'édi...   \n",
            "1                             Merde intergalactique?   \n",
            "2                                Melody m'ennuye....   \n",
            "3                                                bof   \n",
            "4                                         surprenant   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  Quel manque de considération pour les fans qu'...  Musique  negative  \n",
            "1  Que dire de Mika? Le personnage à 2 neurones q...  Musique  negative  \n",
            "2  Dès le premier titre , on est charmé par une v...  Musique   neutral  \n",
            "3  j'ai écouté ce disque par curiosité. c'est bie...  Musique   neutral  \n",
            "4  Surprenant oui, même si la Madonne reprend les...  Musique  positive  \n",
            "Music Test DataFrame saved to CSV:\n",
            "                                             summary  \\\n",
            "0                   Bon ben, on va réécouter Showbiz   \n",
            "1                                            abusé!!   \n",
            "2  Sony \"Music\" ou l'ART de se foutre de la gueul...   \n",
            "3                                   electro à gogo !   \n",
            "4                                              Divin   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  Lorsque Muse a sorti son  , le choc a été gran...  Musique   neutral  \n",
            "1  je suis tres decue du cd, je m'attendais à bcp...  Musique   neutral  \n",
            "2  Quelle honte ce projet!! Sony se fout du monde...  Musique  negative  \n",
            "3  un album plus electro que les précédents. pers...  Musique  positive  \n",
            "4  Les enregistrements de Maria Callas sont un vé...  Musique  positive  \n",
            "Music Unlabeled DataFrame saved to CSV:\n",
            "                                   summary  \\\n",
            "0                                  Ringard   \n",
            "1                              PITOYABLE !   \n",
            "2                                Game Over   \n",
            "3                   déçu, sans surprise...   \n",
            "4  Vous reprendrez bien un peu de tisane !   \n",
            "\n",
            "                                                text category sentiment  \n",
            "0  Ringard, qui esrt ringard si ce n'est que la p...  Musique  negative  \n",
            "1  Pffff...Voilà un type qui n'a jamais su se pos...  Musique  negative  \n",
            "2  Après un BHR très limite, Muse revient avec ce...  Musique   neutral  \n",
            "3  Fan des 3 premiers albums, déçu par BHAR, ce d...  Musique  negative  \n",
            "4  Renan Luce doit être un mec sympa... ses chans...  Musique   neutral  \n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Index(['summary', 'text', 'category', 'sentiment'], dtype='object')\n",
            "Music Train sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     503\n",
            "neutral      497\n",
            "Name: count, dtype: int64\n",
            "Music Test sentiment counts:\n",
            "sentiment\n",
            "positive    1000\n",
            "negative     506\n",
            "neutral      494\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Function to parse XML files and return DataFrames\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for item in root.findall('item'):\n",
        "        summary = item.find('summary').text if item.find('summary') is not None else \"\"\n",
        "        text = item.find('text').text if item.find('text') is not None else \"\"\n",
        "        category = item.find('category').text if item.find('category') is not None else \"\"\n",
        "        rating = item.find('rating').text if item.find('rating') is not None else None\n",
        "        if rating is not None:\n",
        "            rating = float(rating)\n",
        "            if rating > 3:\n",
        "                sentiment = 'positive'\n",
        "            elif rating < 2:\n",
        "                sentiment = 'negative'\n",
        "            else:\n",
        "                sentiment = 'neutral'\n",
        "            data.append((summary, text, category, sentiment))\n",
        "    df = pd.DataFrame(data, columns=['summary', 'text', 'category', 'sentiment'])\n",
        "    return df\n",
        "\n",
        "# Function to process category files\n",
        "def process_category(language, category):\n",
        "    # Define file paths for the category\n",
        "    train_file_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/train.review'\n",
        "    test_file_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/test.review'\n",
        "    unlabeled_file_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/unlabeled.review'\n",
        "\n",
        "    # Parse XML files\n",
        "    train_df = parse_xml_to_df(train_file_path)\n",
        "    test_df = parse_xml_to_df(test_file_path)\n",
        "    unlabeled_df = parse_xml_to_df(unlabeled_file_path)\n",
        "\n",
        "    # Save to CSV\n",
        "    train_csv_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/train.csv'\n",
        "    test_csv_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/test.csv'\n",
        "    unlabeled_csv_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/unlabeled.csv'\n",
        "\n",
        "    train_df.to_csv(train_csv_path, index=False)\n",
        "    test_df.to_csv(test_csv_path, index=False)\n",
        "    unlabeled_df.to_csv(unlabeled_csv_path, index=False)\n",
        "\n",
        "    print(f\"{category.capitalize()} Train DataFrame saved to CSV:\")\n",
        "    print(train_df.head())\n",
        "    print(f\"{category.capitalize()} Test DataFrame saved to CSV:\")\n",
        "    print(test_df.head())\n",
        "    print(f\"{category.capitalize()} Unlabeled DataFrame saved to CSV:\")\n",
        "    print(unlabeled_df.head())\n",
        "\n",
        "    # Verify columns\n",
        "    print(train_df.columns)\n",
        "    print(test_df.columns)\n",
        "    print(unlabeled_df.columns)\n",
        "\n",
        "    # Count positive, neutral, and negative sentiments in train and test data\n",
        "    print(f\"{category.capitalize()} Train sentiment counts:\")\n",
        "    print(train_df['sentiment'].value_counts())\n",
        "    print(f\"{category.capitalize()} Test sentiment counts:\")\n",
        "    print(test_df['sentiment'].value_counts())\n",
        "\n",
        "# Process Japanese categories\n",
        "print(\"Processing Japanese datasets...\")\n",
        "process_category('jp', 'books')\n",
        "process_category('jp', 'dvd')\n",
        "process_category('jp', 'music')\n",
        "\n",
        "# Process French categories\n",
        "print(\"\\nProcessing French datasets...\")\n",
        "process_category('fr', 'books')\n",
        "process_category('fr', 'dvd')\n",
        "process_category('fr', 'music')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cdGoav-AEZV",
        "outputId": "d45fb4e2-cfe8-4b6f-862b-c273d589ea78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "# Function to parse XML files and return DataFrames\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for item in root.findall('item'):\n",
        "        summary = item.find('summary').text if item.find('summary') is not None else \"\"\n",
        "        text = item.find('text').text if item.find('text') is not None else \"\"\n",
        "        category = item.find('category').text if item.find('category') is not None else \"\"\n",
        "        rating = item.find('rating').text if item.find('rating') is not None else None\n",
        "        if rating is not None:\n",
        "            rating = float(rating)\n",
        "            if rating > 3:\n",
        "                sentiment = 'positive'\n",
        "            elif rating < 2:\n",
        "                sentiment = 'negative'\n",
        "            else:\n",
        "                sentiment = 'neutral'\n",
        "            data.append((summary, text, category, sentiment))\n",
        "    df = pd.DataFrame(data, columns=['summary', 'text', 'category', 'sentiment'])\n",
        "    return df\n",
        "\n",
        "# Function to combine data from all categories for a specific language\n",
        "def combine_data(language):\n",
        "    categories = ['books', 'dvd', 'music']\n",
        "    combined_df = pd.DataFrame()\n",
        "\n",
        "    for category in categories:\n",
        "        file_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/train.review'\n",
        "        category_df = parse_xml_to_df(file_path)\n",
        "        combined_df = pd.concat([combined_df, category_df], ignore_index=True)\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "# Combine data for each language\n",
        "de_combined = combine_data('de')\n",
        "fr_combined = combine_data('fr')\n",
        "jp_combined = combine_data('jp')\n",
        "en_combined = combine_data('en')\n",
        "\n",
        "# Save combined data to CSV (optional)\n",
        "de_combined.to_csv('/content/dataset/de_combined.csv', index=False)\n",
        "fr_combined.to_csv('/content/dataset/fr_combined.csv', index=False)\n",
        "jp_combined.to_csv('/content/dataset/jp_combined.csv', index=False)\n",
        "en_combined.to_csv('/content/dataset/en_combined.csv', index=False)\n",
        "\n",
        "print(\"Combined data for German, French, Japanese, and English has been created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciqpqbd5mrbZ",
        "outputId": "94edb217-3713-4692-8706-590342aed6cc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined data for German, French, Japanese, and English has been created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "def train_model(combined_df, language):\n",
        "    # Prepare the data\n",
        "    tokenizer = Tokenizer(num_words=5000)\n",
        "    tokenizer.fit_on_texts(combined_df['text'])\n",
        "    sequences = tokenizer.texts_to_sequences(combined_df['text'])\n",
        "    max_len = 100\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "    # Convert sentiments to numerical values\n",
        "    sentiment_dict = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
        "    y = combined_df['sentiment'].map(sentiment_dict).values\n",
        "\n",
        "    # Build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=5000, output_dim=100, input_length=max_len))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dense(3, activation='softmax'))  # Output layer for 3 classes\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(padded_sequences, y, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "    # Save the model\n",
        "    model.save(f'/content/{language}_model.h5')\n",
        "    print(f\"Model for {language} saved successfully.\")\n",
        "\n",
        "# Train models for each language\n",
        "train_model(de_combined, 'de')\n",
        "train_model(fr_combined, 'fr')\n",
        "train_model(jp_combined, 'jp')\n",
        "train_model(en_combined, 'en')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1n7HH-6muJu",
        "outputId": "ad78d27f-4133-41be-a966-0a8d1ac82a25"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 39s 389ms/step - loss: 0.9610 - accuracy: 0.5452 - val_loss: 0.8426 - val_accuracy: 0.5942\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 30s 395ms/step - loss: 0.6713 - accuracy: 0.6990 - val_loss: 0.8436 - val_accuracy: 0.6175\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 30s 401ms/step - loss: 0.4728 - accuracy: 0.8050 - val_loss: 0.8885 - val_accuracy: 0.6208\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 29s 386ms/step - loss: 0.3090 - accuracy: 0.8823 - val_loss: 1.0413 - val_accuracy: 0.6342\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 26s 351ms/step - loss: 0.1913 - accuracy: 0.9331 - val_loss: 1.2542 - val_accuracy: 0.6258\n",
            "Model for de saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 33s 401ms/step - loss: 0.9806 - accuracy: 0.5129 - val_loss: 0.8569 - val_accuracy: 0.5758\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 28s 368ms/step - loss: 0.6949 - accuracy: 0.6629 - val_loss: 0.8241 - val_accuracy: 0.6108\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 29s 383ms/step - loss: 0.5295 - accuracy: 0.7356 - val_loss: 0.8167 - val_accuracy: 0.6208\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 28s 375ms/step - loss: 0.4055 - accuracy: 0.8238 - val_loss: 0.9536 - val_accuracy: 0.5975\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 31s 408ms/step - loss: 0.2777 - accuracy: 0.8906 - val_loss: 1.0993 - val_accuracy: 0.6417\n",
            "Model for fr saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 34s 394ms/step - loss: 1.0487 - accuracy: 0.4983 - val_loss: 1.0506 - val_accuracy: 0.4850\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 29s 383ms/step - loss: 1.0359 - accuracy: 0.5038 - val_loss: 1.0491 - val_accuracy: 0.4850\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 29s 385ms/step - loss: 1.0045 - accuracy: 0.5190 - val_loss: 1.0796 - val_accuracy: 0.4858\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 29s 387ms/step - loss: 0.9311 - accuracy: 0.5621 - val_loss: 1.0769 - val_accuracy: 0.4817\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 29s 385ms/step - loss: 0.8828 - accuracy: 0.5877 - val_loss: 1.0915 - val_accuracy: 0.4792\n",
            "Model for jp saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 36s 428ms/step - loss: 0.9457 - accuracy: 0.5508 - val_loss: 0.8282 - val_accuracy: 0.6075\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 29s 393ms/step - loss: 0.6831 - accuracy: 0.6848 - val_loss: 0.8242 - val_accuracy: 0.6450\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 30s 401ms/step - loss: 0.5143 - accuracy: 0.7744 - val_loss: 0.8584 - val_accuracy: 0.6483\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 29s 391ms/step - loss: 0.3615 - accuracy: 0.8506 - val_loss: 1.1001 - val_accuracy: 0.6325\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 30s 402ms/step - loss: 0.2572 - accuracy: 0.9002 - val_loss: 1.2038 - val_accuracy: 0.6058\n",
            "Model for en saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Load the tokenizer for each language\n",
        "tokenizers = {\n",
        "    'de': Tokenizer(num_words=5000),\n",
        "    'fr': Tokenizer(num_words=5000),\n",
        "    'jp': Tokenizer(num_words=5000),\n",
        "    'en': Tokenizer(num_words=5000)\n",
        "}\n",
        "\n",
        "# Load the models for each language\n",
        "models = {\n",
        "    'de': load_model('de_model.h5'),  # Update with your model paths\n",
        "    'fr': load_model('fr_model.h5'),\n",
        "    'jp': load_model('jp_model.h5'),\n",
        "    'en': load_model('en_model.h5')\n",
        "}\n",
        "\n",
        "def predict_sentiment(language, comment, category, rating):\n",
        "    # Check if the language is supported\n",
        "    if language not in models:\n",
        "        return \"Language not supported.\"\n",
        "\n",
        "    # Prepare the input text\n",
        "    input_text = f\"{comment} {category} {rating}\"\n",
        "    input_seq = tokenizers[language].texts_to_sequences([input_text])\n",
        "    input_pad = pad_sequences(input_seq, maxlen=100)\n",
        "\n",
        "    # Make the prediction\n",
        "    prediction = models[language].predict(input_pad)\n",
        "    sentiment_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "    # Map the index back to sentiment\n",
        "    sentiment_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "    predicted_sentiment = sentiment_dict[sentiment_index]\n",
        "\n",
        "    # Print debugging information\n",
        "    print(f\"Input text: {input_text}\")\n",
        "    print(f\"Prediction: {prediction}\")\n",
        "    print(f\"Predicted sentiment: {predicted_sentiment}\")\n",
        "\n",
        "    return predicted_sentiment"
      ],
      "metadata": {
        "id": "p6W-Shw0pn4i"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the tokenizer for each language\n",
        "tokenizers = {\n",
        "    'de': Tokenizer(num_words=5000),\n",
        "    'fr': Tokenizer(num_words=5000),\n",
        "    'jp': Tokenizer(num_words=5000),\n",
        "    'en': Tokenizer(num_words=5000)\n",
        "}\n",
        "\n",
        "# Load the models for each language\n",
        "models = {\n",
        "    'de': load_model('de_model.h5'),  # Update with your model paths\n",
        "    'fr': load_model('fr_model.h5'),\n",
        "    'jp': load_model('jp_model.h5'),\n",
        "    'en': load_model('en_model.h5')\n",
        "}\n",
        "\n",
        "# Function to load test data and predict sentiments\n",
        "def evaluate_model(language):\n",
        "    categories = ['books', 'dvd', 'music']  # List of categories\n",
        "    for category in categories:\n",
        "        # Load the test data\n",
        "        test_file_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/test.review'\n",
        "        try:\n",
        "            test_df = parse_xml_to_df(test_file_path)  # Use the same parsing function\n",
        "\n",
        "            # Prepare the input data\n",
        "            input_sequences = tokenizers[language].texts_to_sequences(test_df['text'])\n",
        "            input_pad = pad_sequences(input_sequences, maxlen=100)  # Use the same max_len used during training\n",
        "\n",
        "            # Make predictions\n",
        "            predictions = models[language].predict(input_pad)\n",
        "            predicted_classes = [np.argmax(pred) for pred in predictions]\n",
        "\n",
        "            # Map predicted classes back to sentiment labels\n",
        "            sentiment_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "            predicted_sentiments = [sentiment_dict[pred] for pred in predicted_classes]\n",
        "\n",
        "            # Calculate accuracy and other metrics\n",
        "            accuracy = accuracy_score(test_df['sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2}), predicted_classes)\n",
        "            report = classification_report(test_df['sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2}), predicted_classes)\n",
        "\n",
        "            print(f\"Performance for {language} - {category}:\")\n",
        "            print(f\"Accuracy: {accuracy:.2f}\")\n",
        "            print(\"Classification Report:\")\n",
        "            print(report)\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Test file not found for {language} - {category}. Please check the file path.\")\n",
        "\n",
        "# Evaluate models for all languages\n",
        "for lang in ['de', 'fr', 'jp', 'en']:\n",
        "    evaluate_model(lang)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UXZ7KwGMp3gM",
        "outputId": "d4c05d8b-a85d-422d-ff24-3453f72e1658"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 1891 calls to <function Model.make_predict_function.<locals>.predict_function at 0x79195f350ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 6s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for de - books:\n",
            "Accuracy: 0.28\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      1.00      0.43       551\n",
            "           1       0.00      0.00      0.00       449\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.28      2000\n",
            "   macro avg       0.09      0.33      0.14      2000\n",
            "weighted avg       0.08      0.28      0.12      2000\n",
            "\n",
            "63/63 [==============================] - 6s 89ms/step\n",
            "Performance for de - dvd:\n",
            "Accuracy: 0.28\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      1.00      0.44       566\n",
            "           1       0.00      0.00      0.00       434\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.28      2000\n",
            "   macro avg       0.09      0.33      0.15      2000\n",
            "weighted avg       0.08      0.28      0.12      2000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 4s 69ms/step\n",
            "Performance for de - music:\n",
            "Accuracy: 0.29\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      1.00      0.44       572\n",
            "           1       0.00      0.00      0.00       428\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.29      2000\n",
            "   macro avg       0.10      0.33      0.15      2000\n",
            "weighted avg       0.08      0.29      0.13      2000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 8s 106ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for fr - books:\n",
            "Accuracy: 0.23\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       532\n",
            "           1       0.23      1.00      0.38       468\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.23      2000\n",
            "   macro avg       0.08      0.33      0.13      2000\n",
            "weighted avg       0.05      0.23      0.09      2000\n",
            "\n",
            "63/63 [==============================] - 4s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for fr - dvd:\n",
            "Accuracy: 0.22\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       558\n",
            "           1       0.22      1.00      0.36       442\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.22      2000\n",
            "   macro avg       0.07      0.33      0.12      2000\n",
            "weighted avg       0.05      0.22      0.08      2000\n",
            "\n",
            "63/63 [==============================] - 7s 116ms/step\n",
            "Performance for fr - music:\n",
            "Accuracy: 0.25\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       506\n",
            "           1       0.25      1.00      0.40       494\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.25      2000\n",
            "   macro avg       0.08      0.33      0.13      2000\n",
            "weighted avg       0.06      0.25      0.10      2000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'lower'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-89c1c8bb5d52>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Evaluate models for all languages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'de'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-89c1c8bb5d52>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# Prepare the input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0minput_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0minput_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use the same max_len used during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/text.py\u001b[0m in \u001b[0;36mtexts_to_sequences\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \"\"\"\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtexts_to_sequences_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/text.py\u001b[0m in \u001b[0;36mtexts_to_sequences_generator\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                     seq = text_to_word_sequence(\n\u001b[0m\u001b[1;32m    387\u001b[0m                         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                         \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \"\"\"\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mtranslate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lower'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/content/dataset/cls-acl10-unprocessed'\n",
        "for language in ['de', 'fr', 'jp', 'en']:\n",
        "    for category in ['books', 'dvd', 'music']:\n",
        "        category_path = os.path.join(dataset_path, language, category)\n",
        "        print(f\"Contents of {category_path}:\")\n",
        "        print(os.listdir(category_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbWi3uaqsQC0",
        "outputId": "316ddb59-b890-44a4-b76c-6caeb024612a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content/dataset/cls-acl10-unprocessed/de/books:\n",
            "['test.review', 'train.csv', 'test.csv', 'unlabeled.csv', 'unlabeled.review', '.DS_Store', 'trans', 'train.review']\n",
            "Contents of /content/dataset/cls-acl10-unprocessed/de/dvd:\n",
            "['test.review', 'train.csv', 'test.csv', 'unlabeled.csv', 'unlabeled.review', 'trans', 'train.review']\n",
            "Contents of /content/dataset/cls-acl10-unprocessed/de/music:\n",
            "['test.review', 'train.csv', 'test.csv', 'unlabeled.csv', 'unlabeled_with_predictions.csv', 'unlabeled.review', 'trans', 'train.review']\n",
            "Contents of /content/dataset/cls-acl10-unprocessed/fr/books:\n",
            "['test.review', 'train.csv', 'test.csv', 'unlabeled.csv', 'unlabeled.review', 'trans', 'train.review']\n",
            "Contents of /content/dataset/cls-acl10-unprocessed/fr/dvd:\n",
            "['test.review', 'train.csv', 'test.csv', 'unlabeled.csv', 'unlabeled.review', 'trans', 'train.review']\n",
            "Contents of /content/dataset/cls-acl10-unprocessed/fr/music:\n",
            "['test.review', 'train.csv', 'test.csv', 'unlabeled.csv', 'unlabeled.review', 'trans', 'train.review']\n",
            "Contents of /content/dataset/cls-acl10-unprocessed/jp/books:\n",
            "['test.review', 'train.csv', 'test.csv', 'unlabeled.csv', 'unlabeled.review', 'trans', 'train.review']\n",
            "Contents of /content/dataset/cls-acl10-unprocessed/jp/dvd:\n",
            "['test.review', 'train.csv', 'test.csv', 'unlabeled.csv', 'unlabeled.review', 'trans', 'train.review']\n",
            "Contents of /content/dataset/cls-acl10-unprocessed/jp/music:\n",
            "['test.review', 'train.csv', 'test.csv', 'unlabeled.csv', 'unlabeled.review', 'trans', 'train.review']\n",
            "Contents of /content/dataset/cls-acl10-unprocessed/en/books:\n",
            "['test.review', 'train.csv', 'test.csv', 'unlabeled.csv', 'unlabeled_with_predictions.csv', 'unlabeled.review', 'train.review']\n",
            "Contents of /content/dataset/cls-acl10-unprocessed/en/dvd:\n",
            "['test.review', 'train.csv', 'test.csv', 'unlabeled.csv', 'unlabeled_with_predictions.csv', 'unlabeled.review', 'train.review']\n",
            "Contents of /content/dataset/cls-acl10-unprocessed/en/music:\n",
            "['test.review', 'train.csv', 'test.csv', 'unlabeled.csv', 'unlabeled_with_predictions.csv', 'unlabeled.review', 'train.review']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import pickle\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Function to parse XML files and return DataFrames\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for item in root.findall('item'):\n",
        "        summary = item.find('summary').text if item.find('summary') is not None else \"\"\n",
        "        text = item.find('text').text if item.find('text') is not None else \"\"\n",
        "        category = item.find('category').text if item.find('category') is not None else \"\"\n",
        "        rating = item.find('rating').text if item.find('rating') is not None else None\n",
        "        if rating is not None:\n",
        "            rating = float(rating)\n",
        "            if rating > 3:\n",
        "                sentiment = 'positive'\n",
        "            elif rating < 2:\n",
        "                sentiment = 'negative'\n",
        "            else:\n",
        "                sentiment = 'neutral'\n",
        "            data.append((summary, text, category, sentiment))\n",
        "    df = pd.DataFrame(data, columns=['summary', 'text', 'category', 'sentiment'])\n",
        "    return df\n",
        "\n",
        "# Function to combine data from all categories for a specific language\n",
        "def combine_data(language):\n",
        "    categories = ['books', 'dvd', 'music']\n",
        "    combined_df = pd.DataFrame()\n",
        "\n",
        "    for category in categories:\n",
        "        file_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/train.review'\n",
        "        category_df = parse_xml_to_df(file_path)\n",
        "        combined_df = pd.concat([combined_df, category_df], ignore_index=True)\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(combined_df, language):\n",
        "    # Prepare the data\n",
        "    tokenizer = Tokenizer(num_words=5000)\n",
        "    tokenizer.fit_on_texts(combined_df['text'])\n",
        "    sequences = tokenizer.texts_to_sequences(combined_df['text'])\n",
        "    max_len = 100\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "    # Convert sentiments to numerical values\n",
        "    sentiment_dict = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
        "    y = combined_df['sentiment'].map(sentiment_dict).values\n",
        "\n",
        "    # Build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=5000, output_dim=100, input_length=max_len))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dense(3, activation='softmax'))  # Output layer for 3 classes\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(padded_sequences, y, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "    # Save the model and tokenizer\n",
        "    model.save(f'/content/{language}_model.h5')\n",
        "    with open(f'/content/{language}_tokenizer.pkl', 'wb') as f:\n",
        "        pickle.dump(tokenizer, f)\n",
        "    print(f\"Model for {language} saved successfully.\")\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(language):\n",
        "    categories = ['books', 'dvd', 'music']\n",
        "    for category in categories:\n",
        "        test_file_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/test.review'\n",
        "        try:\n",
        "            test_df = parse_xml_to_df(test_file_path)\n",
        "            print(f\"Evaluating {language} - {category} with {len(test_df)} samples.\")\n",
        "\n",
        "            # Prepare the input data\n",
        "            input_sequences = tokenizers[language].texts_to_sequences(test_df['text'])\n",
        "            input_pad = pad_sequences(input_sequences, maxlen=100)\n",
        "\n",
        "            # Make predictions\n",
        "            predictions = models[language].predict(input_pad)\n",
        "            predicted_classes = [np.argmax(pred) for pred in predictions]\n",
        "\n",
        "            # Calculate accuracy and other metrics\n",
        "            accuracy = accuracy_score(test_df['sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2}), predicted_classes)\n",
        "            report = classification_report(test_df['sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2}), predicted_classes)\n",
        "\n",
        "            print(f\"Performance for {language} - {category}:\")\n",
        "            print(f\"Accuracy: {accuracy:.2f}\")\n",
        "            print(\"Classification Report:\")\n",
        "            print(report)\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Test file not found for {language} - {category}. Please check the file path.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {language} - {category}: {e}\")\n",
        "\n",
        "# Main execution\n",
        "for lang in ['de', 'fr', 'jp', 'en']:\n",
        "    combined_data = combine_data(lang)\n",
        "    train_model(combined_data, lang)\n",
        "\n",
        "# Evaluate models for all languages\n",
        "for lang in ['de', 'fr', 'jp', 'en']:\n",
        "    evaluate_model(lang)\n",
        "\n",
        "# Function to predict sentiment based on user input\n",
        "def predict_sentiment(language, comment, category):\n",
        "    # Load the model and tokenizer\n",
        "    model = load_model(f'/content/{language}_model.h5')\n",
        "    with open(f'/content/{language}_tokenizer.pkl', 'rb') as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "\n",
        "    # Prepare the input text\n",
        "    input_text = f\"{comment} {category}\"\n",
        "    input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    input_pad = pad_sequences(input_seq, maxlen=100)\n",
        "\n",
        "    # Make the prediction\n",
        "    prediction = model.predict(input_pad)\n",
        "    sentiment_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "    # Map the index back to sentiment\n",
        "    sentiment_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "    return sentiment_dict[sentiment_index]\n",
        "\n",
        "# Example usage for user input\n",
        "language = input(\"Enter the language (de/fr/jp/en): \")\n",
        "comment = input(\"Enter your comment: \")\n",
        "category = input(\"Enter the category (books/dvd/music): \")\n",
        "\n",
        "sentiment = predict_sentiment(language, comment, category)\n",
        "print(f\"The predicted sentiment is: {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y29T1pSvtP41",
        "outputId": "19f6291f-08c6-4d9e-b1b0-6a2726452555"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 35s 399ms/step - loss: 0.9777 - accuracy: 0.5367 - val_loss: 0.8571 - val_accuracy: 0.6058\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 30s 393ms/step - loss: 0.6871 - accuracy: 0.6846 - val_loss: 0.8213 - val_accuracy: 0.6267\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 33s 436ms/step - loss: 0.5166 - accuracy: 0.7744 - val_loss: 0.8774 - val_accuracy: 0.6325\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 29s 384ms/step - loss: 0.3566 - accuracy: 0.8629 - val_loss: 0.9967 - val_accuracy: 0.6383\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 29s 392ms/step - loss: 0.2274 - accuracy: 0.9215 - val_loss: 1.2177 - val_accuracy: 0.6158\n",
            "Model for de saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 35s 395ms/step - loss: 0.9663 - accuracy: 0.5331 - val_loss: 0.8699 - val_accuracy: 0.5742\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 31s 418ms/step - loss: 0.6729 - accuracy: 0.6808 - val_loss: 0.7903 - val_accuracy: 0.6192\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 29s 390ms/step - loss: 0.5057 - accuracy: 0.7725 - val_loss: 0.8997 - val_accuracy: 0.6342\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 31s 419ms/step - loss: 0.3462 - accuracy: 0.8594 - val_loss: 1.0111 - val_accuracy: 0.6133\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 30s 399ms/step - loss: 0.2338 - accuracy: 0.9165 - val_loss: 1.2789 - val_accuracy: 0.6383\n",
            "Model for fr saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 35s 405ms/step - loss: 1.0443 - accuracy: 0.5000 - val_loss: 1.0495 - val_accuracy: 0.4850\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 29s 389ms/step - loss: 1.0356 - accuracy: 0.5038 - val_loss: 1.0481 - val_accuracy: 0.4850\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 29s 387ms/step - loss: 0.9962 - accuracy: 0.5196 - val_loss: 1.0840 - val_accuracy: 0.4825\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 29s 389ms/step - loss: 0.9217 - accuracy: 0.5619 - val_loss: 1.1064 - val_accuracy: 0.4800\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 29s 388ms/step - loss: 0.8724 - accuracy: 0.5877 - val_loss: 1.1529 - val_accuracy: 0.4725\n",
            "Model for jp saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 34s 403ms/step - loss: 0.9814 - accuracy: 0.5263 - val_loss: 0.8491 - val_accuracy: 0.6075\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 28s 379ms/step - loss: 0.6999 - accuracy: 0.6762 - val_loss: 0.7807 - val_accuracy: 0.6433\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 32s 423ms/step - loss: 0.5470 - accuracy: 0.7571 - val_loss: 0.8831 - val_accuracy: 0.6625\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 29s 388ms/step - loss: 0.3872 - accuracy: 0.8415 - val_loss: 0.9498 - val_accuracy: 0.6508\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 29s 386ms/step - loss: 0.2816 - accuracy: 0.8908 - val_loss: 1.1128 - val_accuracy: 0.6367\n",
            "Model for en saved successfully.\n",
            "Evaluating de - books with 2000 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 4s 65ms/step\n",
            "Performance for de - books:\n",
            "Accuracy: 0.28\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      1.00      0.43       551\n",
            "           1       0.00      0.00      0.00       449\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.28      2000\n",
            "   macro avg       0.09      0.33      0.14      2000\n",
            "weighted avg       0.08      0.28      0.12      2000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating de - dvd with 2000 samples.\n",
            "63/63 [==============================] - 7s 109ms/step\n",
            "Performance for de - dvd:\n",
            "Accuracy: 0.28\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      1.00      0.44       566\n",
            "           1       0.00      0.00      0.00       434\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.28      2000\n",
            "   macro avg       0.09      0.33      0.15      2000\n",
            "weighted avg       0.08      0.28      0.12      2000\n",
            "\n",
            "Evaluating de - music with 2000 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 5s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for de - music:\n",
            "Accuracy: 0.29\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      1.00      0.44       572\n",
            "           1       0.00      0.00      0.00       428\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.29      2000\n",
            "   macro avg       0.10      0.33      0.15      2000\n",
            "weighted avg       0.08      0.29      0.13      2000\n",
            "\n",
            "Evaluating fr - books with 2000 samples.\n",
            "63/63 [==============================] - 6s 91ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for fr - books:\n",
            "Accuracy: 0.23\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       532\n",
            "           1       0.23      1.00      0.38       468\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.23      2000\n",
            "   macro avg       0.08      0.33      0.13      2000\n",
            "weighted avg       0.05      0.23      0.09      2000\n",
            "\n",
            "Evaluating fr - dvd with 2000 samples.\n",
            "63/63 [==============================] - 4s 71ms/step\n",
            "Performance for fr - dvd:\n",
            "Accuracy: 0.22\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       558\n",
            "           1       0.22      1.00      0.36       442\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.22      2000\n",
            "   macro avg       0.07      0.33      0.12      2000\n",
            "weighted avg       0.05      0.22      0.08      2000\n",
            "\n",
            "Evaluating fr - music with 2000 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 7s 110ms/step\n",
            "Performance for fr - music:\n",
            "Accuracy: 0.25\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       506\n",
            "           1       0.25      1.00      0.40       494\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.25      2000\n",
            "   macro avg       0.08      0.33      0.13      2000\n",
            "weighted avg       0.06      0.25      0.10      2000\n",
            "\n",
            "Evaluating jp - books with 2000 samples.\n",
            "Error processing jp - books: 'NoneType' object has no attribute 'lower'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating jp - dvd with 2000 samples.\n",
            "63/63 [==============================] - 5s 70ms/step\n",
            "Performance for jp - dvd:\n",
            "Accuracy: 0.50\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       532\n",
            "           1       0.00      0.00      0.00       468\n",
            "           2       0.50      1.00      0.67      1000\n",
            "\n",
            "    accuracy                           0.50      2000\n",
            "   macro avg       0.17      0.33      0.22      2000\n",
            "weighted avg       0.25      0.50      0.33      2000\n",
            "\n",
            "Evaluating jp - music with 2000 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 5s 84ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for jp - music:\n",
            "Accuracy: 0.50\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       503\n",
            "           1       0.00      0.00      0.00       497\n",
            "           2       0.50      1.00      0.67      1000\n",
            "\n",
            "    accuracy                           0.50      2000\n",
            "   macro avg       0.17      0.33      0.22      2000\n",
            "weighted avg       0.25      0.50      0.33      2000\n",
            "\n",
            "Evaluating en - books with 2000 samples.\n",
            "63/63 [==============================] - 5s 69ms/step\n",
            "Performance for en - books:\n",
            "Accuracy: 0.27\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      1.00      0.42       538\n",
            "           1       0.00      0.00      0.00       462\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.27      2000\n",
            "   macro avg       0.09      0.33      0.14      2000\n",
            "weighted avg       0.07      0.27      0.11      2000\n",
            "\n",
            "Evaluating en - dvd with 2000 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 7s 108ms/step\n",
            "Performance for en - dvd:\n",
            "Accuracy: 0.29\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      1.00      0.45       577\n",
            "           1       0.00      0.00      0.00       423\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.29      2000\n",
            "   macro avg       0.10      0.33      0.15      2000\n",
            "weighted avg       0.08      0.29      0.13      2000\n",
            "\n",
            "Evaluating en - music with 2000 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 4s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for en - music:\n",
            "Accuracy: 0.27\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      1.00      0.42       535\n",
            "           1       0.00      0.00      0.00       465\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.27      2000\n",
            "   macro avg       0.09      0.33      0.14      2000\n",
            "weighted avg       0.07      0.27      0.11      2000\n",
            "\n",
            "Enter the language (de/fr/jp/en): en\n",
            "Enter your comment: amazing\n",
            "Enter the category (books/dvd/music): books\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "The predicted sentiment is: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "for lang in ['de', 'fr', 'jp', 'en']:\n",
        "    combined_data = combine_data(lang)\n",
        "    train_model(combined_data, lang)\n",
        "\n",
        "# Evaluate models for all languages\n",
        "for lang in ['de', 'fr', 'jp', 'en']:\n",
        "    evaluate_model(lang)\n",
        "\n",
        "# Function to predict sentiment based on user input\n",
        "def predict_sentiment(language, comment, category):\n",
        "    # Load the model and tokenizer\n",
        "    model = load_model(f'/content/{language}_model.h5')\n",
        "    with open(f'/content/{language}_tokenizer.pkl', 'rb') as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "\n",
        "    # Prepare the input text\n",
        "    input_text = f\"{comment} {category}\"\n",
        "    input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    input_pad = pad_sequences(input_seq, maxlen=100)\n",
        "\n",
        "    # Make the prediction\n",
        "    prediction = model.predict(input_pad)\n",
        "    sentiment_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "    # Map the index back to sentiment\n",
        "    sentiment_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "    return sentiment_dict[sentiment_index]\n",
        "\n",
        "# Example usage for user input\n",
        "language = input(\"Enter the language (de/fr/jp/en): \")\n",
        "comment = input(\"Enter your comment: \")\n",
        "category = input(\"Enter the category (books/dvd/music): \")\n",
        "\n",
        "sentiment = predict_sentiment(language, comment, category)\n",
        "print(f\"The predicted sentiment is: {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqsMeGMXttfV",
        "outputId": "8cf9c1b4-509a-4428-ae14-a6da7813a671"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 34s 397ms/step - loss: 0.9600 - accuracy: 0.5444 - val_loss: 0.8296 - val_accuracy: 0.6158\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 30s 401ms/step - loss: 0.6687 - accuracy: 0.6883 - val_loss: 0.8134 - val_accuracy: 0.6375\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 30s 397ms/step - loss: 0.4804 - accuracy: 0.7858 - val_loss: 1.0019 - val_accuracy: 0.6233\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 30s 395ms/step - loss: 0.3250 - accuracy: 0.8679 - val_loss: 1.0252 - val_accuracy: 0.6267\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 28s 368ms/step - loss: 0.2225 - accuracy: 0.9202 - val_loss: 1.1989 - val_accuracy: 0.6317\n",
            "Model for de saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 34s 409ms/step - loss: 0.9848 - accuracy: 0.5300 - val_loss: 0.8449 - val_accuracy: 0.5825\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 29s 387ms/step - loss: 0.6928 - accuracy: 0.6727 - val_loss: 0.8009 - val_accuracy: 0.6008\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 28s 381ms/step - loss: 0.5230 - accuracy: 0.7531 - val_loss: 0.8677 - val_accuracy: 0.6517\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 27s 363ms/step - loss: 0.3549 - accuracy: 0.8540 - val_loss: 1.0471 - val_accuracy: 0.6450\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 27s 361ms/step - loss: 0.2349 - accuracy: 0.9121 - val_loss: 1.1737 - val_accuracy: 0.6325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model for fr saved successfully.\n",
            "Epoch 1/5\n",
            "75/75 [==============================] - 34s 405ms/step - loss: 1.0436 - accuracy: 0.5023 - val_loss: 1.0498 - val_accuracy: 0.4850\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 29s 392ms/step - loss: 1.0376 - accuracy: 0.5038 - val_loss: 1.0484 - val_accuracy: 0.4850\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 29s 391ms/step - loss: 0.9980 - accuracy: 0.5198 - val_loss: 1.0957 - val_accuracy: 0.4833\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 29s 394ms/step - loss: 0.9262 - accuracy: 0.5590 - val_loss: 1.1004 - val_accuracy: 0.4758\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 29s 389ms/step - loss: 0.8742 - accuracy: 0.5902 - val_loss: 1.1349 - val_accuracy: 0.4708\n",
            "Model for jp saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 33s 379ms/step - loss: 0.9733 - accuracy: 0.5294 - val_loss: 0.8403 - val_accuracy: 0.6058\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.7139 - accuracy: 0.6685 - val_loss: 0.8311 - val_accuracy: 0.6200\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 31s 421ms/step - loss: 0.5396 - accuracy: 0.7560 - val_loss: 0.8585 - val_accuracy: 0.6400\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 29s 389ms/step - loss: 0.3888 - accuracy: 0.8358 - val_loss: 1.0175 - val_accuracy: 0.6133\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 28s 376ms/step - loss: 0.2763 - accuracy: 0.8938 - val_loss: 1.1751 - val_accuracy: 0.6275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model for en saved successfully.\n",
            "Evaluating de - books with 2000 samples.\n",
            "63/63 [==============================] - 6s 93ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for de - books:\n",
            "Accuracy: 0.28\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      1.00      0.43       551\n",
            "           1       0.00      0.00      0.00       449\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.28      2000\n",
            "   macro avg       0.09      0.33      0.14      2000\n",
            "weighted avg       0.08      0.28      0.12      2000\n",
            "\n",
            "Evaluating de - dvd with 2000 samples.\n",
            "63/63 [==============================] - 6s 93ms/step\n",
            "Performance for de - dvd:\n",
            "Accuracy: 0.28\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      1.00      0.44       566\n",
            "           1       0.00      0.00      0.00       434\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.28      2000\n",
            "   macro avg       0.09      0.33      0.15      2000\n",
            "weighted avg       0.08      0.28      0.12      2000\n",
            "\n",
            "Evaluating de - music with 2000 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 5s 72ms/step\n",
            "Performance for de - music:\n",
            "Accuracy: 0.29\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      1.00      0.44       572\n",
            "           1       0.00      0.00      0.00       428\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.29      2000\n",
            "   macro avg       0.10      0.33      0.15      2000\n",
            "weighted avg       0.08      0.29      0.13      2000\n",
            "\n",
            "Evaluating fr - books with 2000 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 4s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for fr - books:\n",
            "Accuracy: 0.23\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       532\n",
            "           1       0.23      1.00      0.38       468\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.23      2000\n",
            "   macro avg       0.08      0.33      0.13      2000\n",
            "weighted avg       0.05      0.23      0.09      2000\n",
            "\n",
            "Evaluating fr - dvd with 2000 samples.\n",
            "63/63 [==============================] - 7s 110ms/step\n",
            "Performance for fr - dvd:\n",
            "Accuracy: 0.22\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       558\n",
            "           1       0.22      1.00      0.36       442\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.22      2000\n",
            "   macro avg       0.07      0.33      0.12      2000\n",
            "weighted avg       0.05      0.22      0.08      2000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating fr - music with 2000 samples.\n",
            "63/63 [==============================] - 4s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for fr - music:\n",
            "Accuracy: 0.25\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       506\n",
            "           1       0.25      1.00      0.40       494\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.25      2000\n",
            "   macro avg       0.08      0.33      0.13      2000\n",
            "weighted avg       0.06      0.25      0.10      2000\n",
            "\n",
            "Evaluating jp - books with 2000 samples.\n",
            "Error processing jp - books: 'NoneType' object has no attribute 'lower'\n",
            "Evaluating jp - dvd with 2000 samples.\n",
            "63/63 [==============================] - 6s 94ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for jp - dvd:\n",
            "Accuracy: 0.50\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       532\n",
            "           1       0.00      0.00      0.00       468\n",
            "           2       0.50      1.00      0.67      1000\n",
            "\n",
            "    accuracy                           0.50      2000\n",
            "   macro avg       0.17      0.33      0.22      2000\n",
            "weighted avg       0.25      0.50      0.33      2000\n",
            "\n",
            "Evaluating jp - music with 2000 samples.\n",
            "63/63 [==============================] - 4s 67ms/step\n",
            "Performance for jp - music:\n",
            "Accuracy: 0.50\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       503\n",
            "           1       0.00      0.00      0.00       497\n",
            "           2       0.50      1.00      0.67      1000\n",
            "\n",
            "    accuracy                           0.50      2000\n",
            "   macro avg       0.17      0.33      0.22      2000\n",
            "weighted avg       0.25      0.50      0.33      2000\n",
            "\n",
            "Evaluating en - books with 2000 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 7s 109ms/step\n",
            "Performance for en - books:\n",
            "Accuracy: 0.27\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      1.00      0.42       538\n",
            "           1       0.00      0.00      0.00       462\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.27      2000\n",
            "   macro avg       0.09      0.33      0.14      2000\n",
            "weighted avg       0.07      0.27      0.11      2000\n",
            "\n",
            "Evaluating en - dvd with 2000 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 4s 68ms/step\n",
            "Performance for en - dvd:\n",
            "Accuracy: 0.29\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      1.00      0.45       577\n",
            "           1       0.00      0.00      0.00       423\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.29      2000\n",
            "   macro avg       0.10      0.33      0.15      2000\n",
            "weighted avg       0.08      0.29      0.13      2000\n",
            "\n",
            "Evaluating en - music with 2000 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 4s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for en - music:\n",
            "Accuracy: 0.27\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      1.00      0.42       535\n",
            "           1       0.00      0.00      0.00       465\n",
            "           2       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.27      2000\n",
            "   macro avg       0.09      0.33      0.14      2000\n",
            "weighted avg       0.07      0.27      0.11      2000\n",
            "\n",
            "Enter the language (de/fr/jp/en): en\n",
            "Enter your comment: im happy with the product\n",
            "Enter the category (books/dvd/music): dvd\n",
            "1/1 [==============================] - 1s 875ms/step\n",
            "The predicted sentiment is: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "# Function to parse XML files and return DataFrames\n",
        "def parse_xml_to_df(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "    for item in root.findall('item'):\n",
        "        summary = item.find('summary').text if item.find('summary') is not None else \"\"\n",
        "        text = item.find('text').text if item.find('text') is not None else \"\"\n",
        "        category = item.find('category').text if item.find('category') is not None else \"\"\n",
        "        rating = item.find('rating').text if item.find('rating') is not None else None\n",
        "        if rating is not None:\n",
        "            rating = float(rating)\n",
        "            if rating > 3:\n",
        "                sentiment = 'positive'\n",
        "            elif rating < 2:\n",
        "                sentiment = 'negative'\n",
        "            else:\n",
        "                sentiment = 'neutral'\n",
        "            data.append((summary, text, category, sentiment))\n",
        "    df = pd.DataFrame(data, columns=['summary', 'text', 'category', 'sentiment'])\n",
        "    return df\n",
        "\n",
        "# Function to combine data from all categories for a specific language\n",
        "def combine_data(language):\n",
        "    categories = ['books', 'dvd', 'music']\n",
        "    combined_df = pd.DataFrame()\n",
        "\n",
        "    for category in categories:\n",
        "        file_path = f'/content/dataset/cls-acl10-unprocessed/{language}/{category}/train.review'\n",
        "        category_df = parse_xml_to_df(file_path)\n",
        "        combined_df = pd.concat([combined_df, category_df], ignore_index=True)\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "# Function to preprocess data and create train-test splits\n",
        "def preprocess_data(combined_df):\n",
        "    # Handle missing data\n",
        "    combined_df = combined_df[combined_df['text'].notnull() & (combined_df['text'] != '')]\n",
        "\n",
        "    # Convert sentiments to numerical values\n",
        "    sentiment_dict = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
        "    combined_df['sentiment'] = combined_df['sentiment'].map(sentiment_dict)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(combined_df['text'], combined_df['sentiment'], test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Function to create and compile the BERT model\n",
        "def create_model():\n",
        "    model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) # Pass 'adam' as a string\n",
        "    return model\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(X_train, y_train):\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Tokenize and encode the training data\n",
        "    train_encodings = tokenizer(list(X_train), truncation=True, padding=True, return_tensors='tf', max_length=128)\n",
        "\n",
        "    model = create_model()\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        [train_encodings['input_ids'], train_encodings['attention_mask']],\n",
        "        y_train,\n",
        "        epochs=5,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, tokenizer, X_test, y_test):\n",
        "    # Tokenize and encode the test data\n",
        "    test_encodings = tokenizer(list(X_test), truncation=True, padding=True, return_tensors='tf', max_length=128)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict([test_encodings['input_ids'], test_encodings['attention_mask']])\n",
        "    predicted_classes = np.argmax(predictions.logits, axis=1)\n",
        "\n",
        "    # Calculate accuracy and other metrics\n",
        "    accuracy = accuracy_score(y_test, predicted_classes)\n",
        "    report = classification_report(y_test, predicted_classes)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "\n",
        "# Main execution\n",
        "for lang in ['de', 'fr', 'jp', 'en']:\n",
        "    combined_data = combine_data(lang)\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(combined_data)\n",
        "    model, tokenizer = train_model(X_train, y_train)\n",
        "    evaluate_model(model, tokenizer, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-SgqV166dTg",
        "outputId": "e8e361a8-ff68-4756-be50-2f3dd27a0b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x79196b525a20> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function infer_framework at 0x79196b525a20> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "  9/120 [=>............................] - ETA: 1:25:55 - loss: 2.2262 - accuracy: 0.3333"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f4H4mBqBdDka"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}